{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS in my system :  linux\n",
      "\n",
      "Skriptas zive įrašų transformacijai\n",
      "\n",
      "Išeities duomenys skaitomi iš: /home/kesju/DI/Data/MIT&ZIVE/ZIVE_BUFFER_2022_03_24/records_selected\n",
      "Transformuoti duomenys rašomi į: /home/kesju/DI/Data/MIT&ZIVE/ZIVE_BUFFER_2022_03_24/records_npy\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Atnaujintas variantas, po to, kaip padaryti pakeitimai failų varduose 2022 03 26\n",
    "#\n",
    "# iš originalių Zive įrašų sukuriami įrašai *.npy ir anotacijų failai *.json.\n",
    "\n",
    "# Planas:\n",
    "# sukuriame tuščią dataframe df_list_selected, iš kurio darysime naują list.json\n",
    "# Nuskaitome iš bendros talpyklos list.json\n",
    "# pasidarom sąrašą userId:recordId1, recordId2,.... \n",
    "# ciklas per visus pacientus userId:\n",
    "#   suformuojame sąrašą recordId: ekstrasistolių skaičius ir surušiuojame pagal ekstrasistolių\n",
    "#   skaičių mažėjančia tvarka\n",
    "#   Surikiavus įrašus, įrašus atrenkame tokiu būdu:\n",
    "# \t\ta. Atrenkame pirmiausiai tuos įrašus, kurie turi daugiausiai ekstrasistolių. \n",
    "#       Jei visi įrašai turi ekstrasistolių, tai atrenkame pirmus 10 (iš surikiuotų įrašų pagal ekstrasistolių kiekį).\n",
    "#       Jei ne visi įrašai turi ekstrasistoles, tai atrenkame, tik tuos įrašus, kurie turi ekstrasistoles\n",
    "#       (bet ne daugiau 10 įrašų), ir jei įrašų atrinkta ne daugiau 9, pridedame dar vieną įrašą be ekstrasistolių.\n",
    "# \t\tb. Jei pacientas ekstrasistolių neturi, tai atrenkame ne daugiau vieno (pirmo) to paciento įrašo\n",
    "\n",
    "#   Atrinkus įrašus, papildome df_list_selected  \n",
    "# ciklo per pacientus pabaiga\n",
    "# įrašome visus atrinkus įrašus į record_selected\n",
    "# įrašome df_list_selected į list.json.\n",
    "# išvedame į ekraną suvestinę ir df_list_selected\n",
    "\n",
    "# SubjCode = userNr + recordingNr -- reikia taisyti /////////////////////////////////////////////////////\n",
    "\n",
    "import shutil, sys\n",
    "from icecream import ic\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from zive_util_vu import zive_read_file_1ch, create_dir, create_SubjCode\n",
    "\n",
    "\n",
    "def get_userNr(rec_dir, userId):\n",
    "    # Panaudodami df masyvą df_transl su įrašų numeriais iš ZIVE numerių gauname įrašų eilės numerius\n",
    "    # Jei paciento Nr nėra - užvedamas įrašas\n",
    "    \n",
    "    # Patikriname, ar df_transl egzistuoja. Jei ne, sukuriame ir įrašome pirmą įraša\n",
    "    file_path = Path(rec_dir, 'df_transl.csv')\n",
    "    if (not file_path.exists()):\n",
    "        # Paruošiame masyvą - žodyną numerių vertimui iš userId, registrationId į userNr, registrationNr ir atgal\n",
    "        # ir įrašome į diską\n",
    "        first_rec = {'userId':[userId], 'userNr':[1000] }\n",
    "        df_transl = pd.DataFrame(first_rec)\n",
    "        file_path = Path(rec_dir, 'df_transl.csv')\n",
    "        df_transl.to_csv(file_path)\n",
    "        return df_transl.loc[0, 'userNr']\n",
    "\n",
    "    # Jei egzistuoja, nuskaitome vardų žodyną iš rec_dir aplanko\n",
    "    file_path = Path(rec_dir, 'df_transl.csv')\n",
    "    df_transl = pd.read_csv(file_path, index_col=0)\n",
    "    # print(df_transl)\n",
    "    # Ieškome, ar yra įrašas su userId\n",
    "    # Jei userId nerandame, sukuriame naują įrašą su userId, userNr \n",
    "    if (df_transl.loc[(df_transl['userId'] == userId)]).empty:\n",
    "        userNr = df_transl.loc[len(df_transl)-1, 'userNr'] + 1\n",
    "        print(\"userNr=\", userNr)\n",
    "        new_row = {'userId':userId, 'userNr':userNr}\n",
    "        df_transl = df_transl.append(new_row, ignore_index=True)\n",
    "        file_path = Path(rec_dir, 'df_transl.csv')\n",
    "        df_transl.to_csv(file_path)\n",
    "        return userNr\n",
    "    else:\n",
    "        # Jei userId randame, gražiname userNr\n",
    "        row = df_transl.loc[(df_transl['userId'] == userId)]\n",
    "        return row['userNr'].values[0]\n",
    "\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "my_os=sys.platform\n",
    "print(\"OS in my system : \",my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'C:\\DI\\Data\\MIT&ZIVE'   # variantas: Windows\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI/Data/MIT&ZIVE'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "# Vietinės talpyklos aplankas\n",
    "db_folder = 'ZIVE_BUFFER_2022_03_24'\n",
    "\n",
    "# Nuoroda į aplanką su EKG duomenų rinkiniu\n",
    "db_path = Path(Duomenu_aplankas, db_folder)\n",
    "\n",
    "rec_dir = Path(db_path,'records_selected')\n",
    "\n",
    "# Nuoroda į aplanką su transformuotu EKG duomenų rinkiniu\n",
    "rec_dir_npy = Path(db_path, 'records_npy')\n",
    "\n",
    "# Paliekamų anotacijų sąrašas\n",
    "annot_list = ['N','S','V','U']\n",
    "\n",
    "# Diskretizavimo dažnis\n",
    "fs_zive = 200\n",
    "\n",
    "print(\"\\nSkriptas zive įrašų transformacijai\\n\")\n",
    "\n",
    "print(\"Išeities duomenys skaitomi iš:\", rec_dir)\n",
    "print(\"Transformuoti duomenys rašomi į:\", rec_dir_npy)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/kesju/DI/Data/MIT&ZIVE/ZIVE_BUFFER_2022_03_24/records_npy' already exists\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f7bb9a2eee0>\n",
      "\n",
      "\n",
      "userNr= 1001\n",
      "userNr= 1002\n",
      "userNr= 1003\n",
      "['1000.1631134.867', '1001.1631076.286', '1002.1630844.567', '1003.1636452.484']\n",
      "\n",
      "Schemos parametrai įrašyti į failą:  /home/kesju/DI/Data/MIT&ZIVE/ZIVE_BUFFER_2022_03_24/records_npy/info_create_z.json \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2117/219879182.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_transl = df_transl.append(new_row, ignore_index=True)\n",
      "/tmp/ipykernel_2117/219879182.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_transl = df_transl.append(new_row, ignore_index=True)\n",
      "/tmp/ipykernel_2117/219879182.py:62: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_transl = df_transl.append(new_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sukūriame aplanką EKG sekų įrašymui\n",
    "create_dir(rec_dir_npy)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1000, \"display.max_columns\", 20)\n",
    "pd.set_option('display.width', 2000)\n",
    "\n",
    "# Nuskaitome Zive įrašų talpykloje laikomų įrašų sąrašą\n",
    "file_path = Path(rec_dir, 'list.json')\n",
    "with open(file_path,'r', encoding='UTF-8', errors = 'ignore') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "df_list = pd.json_normalize(data, record_path =['data'])\n",
    "\n",
    "# print(df_list)\n",
    "# Sugrupuojame įrašus į to paties paciento grupes\n",
    "grouped = df_list.groupby(['userId','file_name'])\n",
    "print(grouped)\n",
    "print(\"\\n\")\n",
    "\n",
    "SubjCodes = []\n",
    "\n",
    "# Perrašome įrašus nauju formatu į kitą folderį\n",
    "for key in grouped.groups:\n",
    "    userId = key[0]\n",
    "    file_name = str(key[1])\n",
    "    \n",
    "    userNr = get_userNr(rec_dir_npy, userId)\n",
    "    SubjCode = create_SubjCode(userNr, file_name)  \n",
    "    # print(\"SubjCode: \", SubjCode, userNr, file_name)\n",
    "\n",
    "    SubjCodes.append(SubjCode)\n",
    "\n",
    "    file_path = Path(rec_dir, file_name)\n",
    "    signal = zive_read_file_1ch(file_path)  \n",
    "\n",
    "    file_path = Path(rec_dir_npy, str(SubjCode) + '.npy')\n",
    "    with open(file_path, 'wb') as f:\n",
    "        np.save(f, signal)\n",
    "\n",
    "    src = Path(rec_dir, file_name + '.json')\n",
    "    dst = Path(rec_dir_npy, str(SubjCode) + '.json')\n",
    "    shutil.copy2(src, dst)\n",
    "\n",
    "print(SubjCodes)\n",
    "\n",
    "info = {\n",
    "    'db_folder':db_folder,\n",
    "    'fs': fs_zive,\n",
    "    'SubjCodes':SubjCodes,\n",
    "    'annot_list':annot_list\n",
    "    }\n",
    "\n",
    "file_name = Path(rec_dir_npy,'info_create_z.json')\n",
    "with open(file_name, 'w') as f:\n",
    "    json.dump(info, f)\n",
    "    \n",
    "print(\"\\nSchemos parametrai įrašyti į failą: \", file_name, \"\\n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Viso pacientų: 4  EKG įrašų: 4\n",
      "\n",
      "Įrašų pasiskirstymas per pacientus\n",
      "                            N   S    V  U  flag  count\n",
      "userID                                                \n",
      "613b1d673d08d4d1f3cdc8f8  656  12    0  0     0      1\n",
      "6144c4fbbd0cc552e427535f  541   0  194  0     0      1\n",
      "6144c5b1bd0cc5a681275363  903   0    0  0     0      1\n",
      "6190d4b23cd1d29db2303ce9  600  11    2  0     0      1\n",
      "\n",
      "Failų sąrašas įrašytas:  /home/kesju/DI/Data/MIT&ZIVE/ZIVE_BUFFER_2022_03_24/records_npy/list.json\n"
     ]
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/python-shutil-copy2-method/#:~:text=shutil.copy\n",
    "# 2%20%28%29%20method%20in%20Python%20is%20used%20to,destination%20can%20be%20a%20file%20or%20a%20directory.\n",
    "\n",
    "# Susirandame anotacijų pasiskirstymą per pacientus ir pacientų skaičių\n",
    "df_sum = df_list.groupby(['userId'],sort = False).sum()\n",
    "# print(df_sum)\n",
    "# https://sparkbyexamples.com/pandas/pandas-groupby-sum-examples/\n",
    "count = df_list['userId'].value_counts()\n",
    "print(f'\\nViso pacientų: {len(count)}  EKG įrašų: {len(df_list)}')\n",
    "print(f'\\nĮrašų pasiskirstymas per pacientus')\n",
    "count = count.rename(\"count\")\n",
    "frames = [df_sum, count]\n",
    "result = pd.concat(frames, axis = 1)\n",
    "result.index.rename ('userID', inplace= True)\n",
    "result.drop(labels=['incl'], axis=1, inplace=True)\n",
    "# https://www.shanelynn.ie/pandas-drop-delete-dataframe-rows-columns/\n",
    "print(result)\n",
    "\n",
    "# Įrašome failų sąrašą į diską\n",
    "file_path = Path(rec_dir_npy,'list.json')       \n",
    "df_list.to_json(file_path, orient = 'table', index=False)\n",
    "print(f'\\nFailų sąrašas įrašytas:  {file_path}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fdd05f7b6e7f46fd1f1bbcbfdc9d8b4b1f98b078b306375c0cb77e6ad3f81a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ecg': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
