{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS in my system :  linux\n",
      "\n",
      "Skriptas skirtas zive EKG įrašuose esančių pūpsnių atributų sarašui all_beats_attr sukurti\n",
      "\n",
      "Bendras Zive duomenų aplankas:  /home/kesju/DI/Data/MIT&ZIVE/VU\n",
      "Zive EKG įrašų aplankas:  /home/kesju/DI/Data/MIT&ZIVE/VU/DUOM_VU/records_npy\n",
      "EKG įrašų atributų sąrašas: list_npy.json\n",
      "Diskretizavimo dažnis:  200\n",
      "\n",
      "Pacientų įrašų kodų sąrašas:\n",
      " [10000, 10001, 10002, 10010, 10011, 10012, 10013, 10014, 10015, 10020, 10021, 10022, 10023, 10024, 10025, 10026, 10030, 10031, 10040, 10041, 10042, 10050, 10051, 10052, 10053, 10054, 10055, 10056, 10057, 10058, 10059, 10060, 10061, 10062, 10063, 10070, 10071, 10080, 10081, 10082, 10083, 10084, 10085, 10086, 10087, 10088, 10089, 10090, 10091, 10092, 10093, 10094, 10095, 10096, 10097, 10098, 10099, 10100, 10101, 10110, 10111, 10112, 10120, 10121, 10122, 10130, 10131, 10132, 10133, 10134, 10135, 10136, 10137, 10138, 10139, 10140, 10150, 10151, 10152, 10153, 10154, 10155, 10156, 10157, 10158, 10159, 10160, 10161, 10170, 10180, 10181, 10182, 10183, 10184, 10185, 10186, 10187, 10188, 10190, 10191, 10192, 10193, 10194, 10195, 10196, 10197, 10198, 10199, 10200, 10201, 10202, 10210, 10220, 10230, 10240, 10241, 10250, 10251, 10252, 10253, 10254, 10260, 10261, 10262, 10263, 10264, 10265, 10266, 10267, 10268, 10269, 10270, 10271, 10272, 10273, 10274, 10280, 10281, 10282, 10283, 10290, 10291, 10300, 10301, 10302, 10303, 10304, 10305, 10306, 10307, 10308, 10309, 10310, 10311, 10312, 10313, 10314, 10315, 10316, 10317, 10318, 10319, 10320, 10330, 10331, 10332, 10333, 10334, 10335, 10336, 10340, 10350, 10351, 10352, 10353, 10354, 10355, 10356, 10357, 10358, 10359, 10360, 10361, 10370, 10371, 10372, 10373, 10374, 10375, 10376, 10377, 10380, 10390, 10400, 10401, 10402, 10403, 10404, 10410, 10411, 10420, 10421, 10422, 10423, 10424, 10425, 10426, 10427, 10428, 10429, 10430, 10431, 10440, 10450, 10460, 10470, 10480, 10481, 10490, 10500, 10501, 10502, 10503, 10504, 10505, 10506, 10510, 10511, 10520, 10521, 10522, 10523, 10524, 10525, 10526, 10527, 10528, 10529, 10530, 10531, 10532, 10533, 10534, 10535, 10536, 10537, 10538, 10539, 10540, 10541, 10542, 10543, 10544, 10545, 10546, 10547, 10548, 10549, 10550, 10551, 10552, 10553, 10554, 10555, 10560, 10561, 10562, 10563, 10564, 10565, 10566, 10567, 10568, 10569, 10570, 10571, 10572, 10573, 10574, 10575, 10576, 10580, 10581, 10582, 10590, 10591, 10600, 10601, 10602, 10610, 10620, 10621, 10630, 10631, 10640, 10641, 10642, 10643, 10644, 10645, 10646, 10647, 10648, 10649, 10650, 10651, 10652, 10653, 10654, 10655, 10656, 10657, 10658, 10659, 10660, 10661, 10662, 10663, 10664, 10665, 10670, 10671, 10672, 10673, 10674, 10675, 10676, 10677, 10678, 10679, 10680, 10681, 10682, 10690, 10691, 10692, 10693, 10694, 10695, 10700, 10701, 10702, 10703, 10704, 10705, 10706, 10707, 10708, 10709, 10710, 10711, 10712, 10713, 10714, 10715, 10716, 10717, 10718, 10719, 10720, 10721, 10722, 10723, 10724, 10725, 10726, 10727, 10728, 10729, 10730, 10731, 10740, 10741, 10742, 10743, 10744, 10745, 10746, 10747, 10748, 10749, 10750, 10751, 10752, 10753, 10754, 10755, 10756, 10757, 10760, 10770, 10771, 10772, 10773, 10774, 10775, 10776, 10777, 10778, 10779, 10780, 10790, 10791, 10792, 10793, 10794, 10795, 10796, 10797, 10798, 10799, 10800, 10801, 10802, 10803, 10804, 10805, 10806, 10807, 10808, 10809, 10810, 10811, 10812, 10813, 10814, 10815, 10816, 10817, 10818, 10819, 10820, 10830, 10831, 10832, 10833, 10840, 10841, 10842, 10843, 10844, 10845, 10846, 10847, 10848, 10849, 10850, 10860, 10861, 10862, 10863, 10864, 10865, 10866, 10867, 10868, 10869]\n",
      "\n",
      "Anotacijų sąrašas:\n",
      " ['N', 'S', 'V', 'U']\n"
     ]
    }
   ],
   "source": [
    "# Skriptas pūpsnių atributų masyvui all_beats_attr sukurimui, o taip pat pacientų padalijimui\n",
    "# į dalis: train, validate, test, sukuria tų dalių SubjCode sąrašus ir įrašo juos į diską.\n",
    "#  \n",
    "# Atnaujintas variantas, po to, kaip padaryti pakeitimai failų varduose 2022 03 26\n",
    "#\n",
    "# Skriptas zive_creat_beats_attrib skirtas zive EKG įrašuose esančių pūpsnių atributų masyvui\n",
    "# all_beats_attr sukurti, kad būtų galima juos panaudoti sekų formavimui:\n",
    "# - atsikratome nepageidaujamų anotacijų: 'U'  ------- ///////////////////// pataisyti, neatsikratyti\n",
    "# - iš anotacijų suformuojame klasių numerius\n",
    "# - apskaičiuojami ir į atributus įrašomi RR intervalai: RRl, RRr. Atributų eilutėse,\n",
    "#  atitinkančios pirmą ir paskutinį pūpsnį, RRl ir RRr reikšmės lygios ???????????????????????????????????????\n",
    "#  sentinel = -1  - nereikia, skaičiuojama programiškai /////////////// ///////////////////////\n",
    "\n",
    "# Pacientų kodų sąrašas SubjCodes (userNr+file_name) paimamas iš list_npy.json, kurį\n",
    "# suformuoja zive_create_npy. Masyvas all_beats_attr įrašomas į failą all_beats_attr_z.csv.\n",
    "\n",
    "# Toliau pacientai sudalijami į dalis: train, validate, test. Šioms dalims sukūriami pacientų įrašų vardų SubjCode\n",
    "# sąrašai train_subjcode_lst, validate_subjcode_lst, test_subjcode_lst ir jie įrašomi į diską, kur paskui bus\n",
    "# naudojami indeksų generavimui.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from icecream import ic\n",
    "import json, time, sys\n",
    "\n",
    "from zive_util_vu import runtime, read_rec_attrib, split_SubjCode, get_annotations_table, print_annotations_table\n",
    "\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def print_df_list(df_list, flag1=True, flag2=True):\n",
    "    if flag1:\n",
    "        print(df_list[['SubjCode', 'file_name',  'N',   'S',    'V',   'U']])\n",
    "    if flag2:\n",
    "        sum = np.zeros(4,'int')\n",
    "        # print(' '*5, 'N',   'S',   'V',  'U')\n",
    "        sum[0] = df_list.iloc[:, 4].sum()\n",
    "        sum[1] = df_list.iloc[:, 5].sum()\n",
    "        sum[2] = df_list.iloc[:, 6].sum()\n",
    "        sum[3] = df_list.iloc[:, 7].sum()\n",
    "        total = sum.sum()\n",
    "        str =f\"\\nN:{int(sum[0]):>7}  S:{(int(sum[1])):5}  V:{int(sum[2]):5}  U:{int(sum[3]):4}  total:{total:>7}\" \n",
    "        print(str)\n",
    "\n",
    "my_os=sys.platform\n",
    "\n",
    "print(\"OS in my system : \",my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Pasiruošimas\n",
    "\n",
    "# //////////////// NURODOMI PARAMETRAI /////////////////////////////////////////////////////\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'D:\\DI\\Data\\MIT&ZIVE\\VU'   # variantas: Windows\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI/Data/MIT&ZIVE/VU'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "#  MIT2ZIVE duomenų aplankas\n",
    "db_folder = 'DUOM_VU'\n",
    "\n",
    "# Aplankas su MIT2ZIVE EKG įrašais (.npy) ir anotacijomis (.json)\n",
    "rec_folder = 'records_npy'\n",
    "rec_list_npy = 'list_npy.json'\n",
    "train_beats_attr_fname ='all_beats_attr_z.csv'\n",
    "\n",
    "# Kas kiek išvedamas apdorotų duomenų skaičius\n",
    "show_period = 100\n",
    "\n",
    "# Failai pūpsnių klasių formavimui\n",
    "annot_grouping = {'N':'N', 'S':'S', 'V':'V', 'U':'U'}\n",
    "selected_beats = {'N':0, 'S':1, 'V':2, 'U':3}\n",
    "\n",
    "# ///////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Nuoroda į MIT2ZIVE duomenų aplanką\n",
    "db_path = Path(Duomenu_aplankas, db_folder)\n",
    "\n",
    "# Nuoroda į aplanką su MIT2ZIVE EKG įrašais (.npa) ir anotacijomis (.json)\n",
    "rec_dir = Path(db_path, rec_folder)\n",
    "\n",
    "# Nuskaitome failą info_create.json ir duomenų rinkinio parametrus\n",
    "file_path = Path(rec_dir,'info_create_z.json')\n",
    "with open(file_path) as json_file:\n",
    "    info_create = json.load(json_file)\n",
    "\n",
    "fs = info_create['fs'] # diskretizavimo dažnumas\n",
    "SubjCodes =  info_create['SubjCodes'] # pacientų įrašų sąrašas\n",
    "annot_list  = info_create['annot_list'] # anotacijų sąrašas\n",
    "# print(annot_list)\n",
    "\n",
    "# Susikuriame pagalbinį anotacijų žodyną - dictionary beats_annot\n",
    "nr_sequence = list(range(13))\n",
    "beats_annot = dict(zip(annot_list, nr_sequence))\n",
    "\n",
    "print(\"\\nSkriptas skirtas zive EKG įrašuose esančių pūpsnių atributų sarašui all_beats_attr sukurti\")\n",
    "print(\"\\nBendras Zive duomenų aplankas: \", Duomenu_aplankas)\n",
    "print(\"Zive EKG įrašų aplankas: \", rec_dir)\n",
    "print(\"EKG įrašų atributų sąrašas:\", rec_list_npy)\n",
    "\n",
    "print(\"Diskretizavimo dažnis: \", fs)\n",
    "print(\"\\nPacientų įrašų kodų sąrašas:\\n\",SubjCodes)\n",
    "print(\"\\nAnotacijų sąrašas:\\n\", annot_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EKG įrašams suformuojamas pūpsnių atributų freimas ir įrašomas į diską\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8843/1918246011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# for SubjCode in SubjCodes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mSubjCode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SubjCode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nECG įrašas:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubjCode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_list' is not defined"
     ]
    }
   ],
   "source": [
    "# II-a dalis. zive EKG įrašai analizuojami, formuojamas freimas all_beats_attr ir  įrašomas į diską. \n",
    "\n",
    "# from zive_util import print_annotations_table\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1000, \"display.max_columns\", 19)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Nuskaitomas įrašų sąrašas, suformuojamas atitinkamas dataframe df_list\n",
    "file_path = Path(rec_dir, rec_list_npy)\n",
    "with open(file_path,'r', encoding='UTF-8', errors = 'ignore') as f:\n",
    "    data = json.loads(f.read())\n",
    "df_list = pd.json_normalize(data, record_path =['data'])\n",
    "print(\"\\ndf_list:\")\n",
    "print_df_list(df_list)\n",
    "\n",
    "# Susirandame anotacijų pasiskirstymą per įrašus\n",
    "annot_list = ['N', 'S', 'V', 'U']\n",
    "# Susikuriame pagalbinį anotacijų žodyną - dictionary beats_annot\n",
    "nr_sequence = list(range(len(annot_list)))\n",
    "beats_annot = dict(zip(annot_list, nr_sequence))\n",
    "# print(beats_annot)\n",
    "\n",
    "print(\"\\nEKG įrašams suformuojamas pūpsnių atributų freimas ir įrašomas į diską\")\n",
    "\n",
    "# Pacientų įrašų sąrašas bandymams:\n",
    "# SubjCodes = ['10001']\n",
    "\n",
    "# Sukūriame masyvą sekų atributų sąrašo kaupimui\n",
    "all_beats_attr = pd.DataFrame({'userNr': pd.Series(dtype='int'),\n",
    "                   'recordingNr': pd.Series(dtype='int'),\n",
    "                   'sample': pd.Series(dtype='int'),\n",
    "                   'symbol': pd.Series(dtype='str')})\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# CIKLAS PER PACIENTŲ ĮRAŠUS\n",
    "\n",
    "# for SubjCode in SubjCodes:\n",
    "for idx, row in df_list.iterrows():    \n",
    "    SubjCode = row['SubjCode']\n",
    "    print(\"\\nECG įrašas:\", SubjCode)\n",
    "    \n",
    "    # Paciento anotacijų ir EKG įrašų nuskaitymas, sekų išpjovimas ir įrašymas, sekų atributų formavimas\n",
    "\n",
    "    # Nuskaitome paciento anotacijas ir jų indeksus\n",
    "    atr_sample, atr_symbol = read_rec_attrib(rec_dir, SubjCode)\n",
    "\n",
    "    subject_labels = []\n",
    "    beat_nr = 0\n",
    "    icycle = 0\n",
    "\n",
    "    # Ciklas per visas paciento įrašo anotacijas (simbolius) ir jų vietas (i_sample)\n",
    "    for i, i_sample in enumerate(atr_sample):\n",
    "    \n",
    "        icycle +=1\n",
    "        if (icycle%show_period == 0):\n",
    "            print(icycle, end =' ') \n",
    "\n",
    "        # Formuojame pūpsnio atributus\n",
    "        userNr, recordingNr = split_SubjCode(SubjCode)\n",
    "\n",
    "        beats_attr = {'userNr':int(userNr), 'recordingNr':int(recordingNr), 'sample':int(i_sample), 'symbol':str(atr_symbol[i])}\n",
    "        \n",
    "        # Senas variantas\n",
    "        # train_beats_attr = train_beats_attr.append(beats_attr, ignore_index=True)\n",
    "\n",
    "        # Variantas su concat\n",
    "        df_new_row = pd.DataFrame([beats_attr])\n",
    "        all_beats_attr = pd.concat([all_beats_attr, df_new_row])\n",
    "\n",
    "        # Galima perrašyti ir kitaip, naudojant pd.DataFrame.from_records\n",
    "        # all_beats_attr = pd.concat([all_beats_attr, pd.DataFrame.from_records([beats_attr])])\n",
    "\n",
    "        beat_nr +=1\n",
    "\n",
    "\n",
    "# Ciklo per pacientų įrašus pabaiga\n",
    "\n",
    "# Atsikratome nepageidaujamų anotacijų: 'U'\n",
    "# index_names = train_beats_attr[train_beats_attr['symbol'].isin(['U'])].index\n",
    "# train_beats_attr.drop(index_names, inplace = True)\n",
    "# print(train_beats_attr.info())\n",
    "\n",
    "# Pernumeruojame indeksus, kad būtų nuo 0 iš eilės\n",
    "all_beats_attr.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Iš anotacijų suformuojame klasių numerius ir pridedame, kaip naują stulpelį\n",
    "annot_labels = {key:selected_beats[value] for key, value in annot_grouping.items()}\n",
    "labels_from_annot = all_beats_attr['symbol'].replace(annot_labels, inplace=False)\n",
    "all_beats_attr['label'] = labels_from_annot\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\nVisi duomenys\\n\")\n",
    "labels_table, labels_sums = get_annotations_table(all_beats_attr)\n",
    "print_annotations_table(labels_table, labels_sums, Flag1=True, Flag2=False)\n",
    "\n",
    "# Įrašome sekos atributų masyvą į seq_dir aplanką\n",
    "file_path = Path(rec_dir, train_beats_attr_fname)\n",
    "all_beats_attr.index.name = \"id\"\n",
    "\n",
    "all_beats_attr.to_csv(file_path, )\n",
    "print(\"\\nAtributų freimas įrašytas: į \", file_path, \"\\n\" )\n",
    "\n",
    "end_time = time.time()\n",
    "print('\\n')\n",
    "runtime(end_time-start_time)\n",
    "\n",
    "print(\"\\nPabaiga.............\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  III-a dalis. SUDALIJAME PACIENTUS IR JŲ ĮRAŠUS Į TRAIN, VALIDATION IR TEST DALIS\n",
    "# Gausime df_train, df_validation, df_test, atitinkamus SubjCodes sąrašus įrašome į diską\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n",
    "                                         frac_train=0.6, frac_val=0.15, frac_test=0.25,\n",
    "                                         random_state=None):\n",
    "    '''\n",
    "    https://localcoder.org/stratified-splitting-of-pandas-dataframe-into-training-validation-and-test-set\n",
    "\n",
    "    Splits a Pandas dataframe into three subsets (train, val, and test)\n",
    "    following fractional ratios provided by the user, where each subset is\n",
    "    stratified by the values in a specific column (that is, each subset has\n",
    "    the same relative frequency of the values in the column). It performs this\n",
    "    splitting by running train_test_split() twice.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_input : Pandas dataframe\n",
    "        Input dataframe to be split.\n",
    "    stratify_colname : str\n",
    "        The name of the column that will be used for stratification. Usually\n",
    "        this column would be for the label.\n",
    "    frac_train : float\n",
    "    frac_val   : float\n",
    "    frac_test  : float\n",
    "        The ratios with which the dataframe will be split into train, val, and\n",
    "        test data. The values should be expressed as float fractions and should\n",
    "        sum to 1.0.\n",
    "    random_state : int, None, or RandomStateInstance\n",
    "        Value to be passed to train_test_split().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_train, df_val, df_test :\n",
    "        Dataframes containing the three splits.\n",
    "    '''\n",
    "\n",
    "    if frac_train + frac_val + frac_test != 1.0:\n",
    "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n",
    "                         (frac_train, frac_val, frac_test))\n",
    "\n",
    "    if stratify_colname not in df_input.columns:\n",
    "        raise ValueError('%s is not a column in the dataframe' % (stratify_colname))\n",
    "\n",
    "    X = df_input # Contains all columns.\n",
    "    y = df_input[[stratify_colname]] # Dataframe of just the column on which to stratify.\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp, y_train, y_temp = train_test_split(X,\n",
    "                                                          y,\n",
    "                                                          stratify=y,\n",
    "                                                          test_size=(1.0 - frac_train),\n",
    "                                                          random_state=random_state)\n",
    "\n",
    "    # Split the temp dataframe into val and test dataframes.\n",
    "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
    "    df_val, df_test, y_val, y_test = train_test_split(df_temp,\n",
    "                                                      y_temp,\n",
    "                                                      stratify=y_temp,\n",
    "                                                      test_size=relative_frac_test,\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "\n",
    "print(\"\\nII-a dalis. SUDALIJAME PACIENTUS IR JŲ ĮRAŠUS Į TRAIN, VALIDATION IR TEST DALIS\")\n",
    "\n",
    "# Surenkame informaciją apie pacientus\n",
    "\n",
    "df_sum = df_list.groupby(['userId'],sort = False).sum()\n",
    "# print(df_sum)\n",
    "# https://sparkbyexamples.com/pandas/pandas-groupby-sum-examples/\n",
    "count = df_list['userId'].value_counts()\n",
    "print(f'\\nViso pacientų: {len(count)}  EKG įrašų: {len(df_list)}')\n",
    "print(f'\\nĮrašų pasiskirstymas per pacientus')\n",
    "count = count.rename(\"count\")\n",
    "frames = [df_sum, count]\n",
    "result = pd.concat(frames, axis = 1)\n",
    "result.index.rename ('userId', inplace= True)\n",
    "# https://www.shanelynn.ie/pandas-drop-delete-dataframe-rows-columns/\n",
    "\n",
    "print(result[['N',   'S',    'V',   'U', 'count']])\n",
    "\n",
    "# Išplečiame freimą result iki pozymio user_type, kurį naudosime kaip stratify splitinant į train, test\n",
    "\n",
    "# Nustatome user_type pagal bendrus 'S' ir 'V' skaičius per visus paciento įrašus \n",
    "# user_type == 0, jei  bendras skaičius 'S'==0 ir bendras skaičius 'V'==0\n",
    "# user_type == 1, jei  bendras skaičius 'S'> 0 ir bendras skaičius 'V'==0\n",
    "# user_type == 2, jei  bendras skaičius 'S'==0 ir bendras skaičius 'V'> 0\n",
    "# user_type == 3, jei  bendras skaičius 'S'> 0 ir bendras skaičius 'V'>0\n",
    "\n",
    "result = result.reset_index()\n",
    "user_types = np.zeros(len(result), dtype = int )\n",
    "userIds = []\n",
    "for i, row in result.iterrows():\n",
    "    # print(row)\n",
    "    userIds.append(row['userId'])\n",
    "    if ((row['S'] == 0) & (row['V'] == 0)):\n",
    "        user_types[i] = 0\n",
    "    if ((row['S'] > 0) & (row['V'] == 0)):\n",
    "        user_types[i] = 1\n",
    "    if ((row['S'] == 0) & (row['V'] > 0)):\n",
    "        user_types[i] = 2\n",
    "    if ((row['S'] > 0) & (row['V'] > 0)):\n",
    "        user_types[i] = 3\n",
    "\n",
    "# print(userIds)\n",
    "\n",
    "# df_userId = pd.DataFrame(columns = ['userId', 'user_types'])\n",
    "df_userId = pd.DataFrame()\n",
    "df_userId['userID'] = userIds\n",
    "df_userId['user_types'] = user_types\n",
    "\n",
    "print(\"\\ndf_user_Id:\\n\", df_userId)\n",
    "\n",
    "# print(user_types)\n",
    "# result['user_type'] = user_types\n",
    "# print(\"\\nresult\\n\", result)\n",
    "\n",
    "frac_train=0.35\n",
    "frac_val=0.35\n",
    "frac_test=0.3\n",
    "train, validation, test = split_stratified_into_train_val_test(df_userId, stratify_colname='user_types',\n",
    "                                        frac_train=frac_train, frac_val=frac_val, frac_test=frac_test, random_state=None)\n",
    "\n",
    "# print(\"\\ntrain\\n\", train)\n",
    "# print(\"\\nvalidate\\n\", test)\n",
    "# print(\"\\ntest\\n\", test)\n",
    "\n",
    "print(f\"frac_train: {frac_train}, frac_val: {frac_val}, frac_test: {frac_test}\")\n",
    "df_train = df_list.loc[df_list['userId'].isin(list(train['userID']))]\n",
    "print(\"\\ndf_train:\")\n",
    "print_df_list(df_train, False, True)\n",
    "train_subjcode_lst = list(df_train['SubjCode'])\n",
    "print(train_subjcode_lst)\n",
    "file_path = Path(rec_dir, 'train_subjcode_lst.csv')\n",
    "np.savetxt(file_path, np.array(train_subjcode_lst), delimiter=',', fmt='%d')\n",
    "print(f\"\\nMokymo imties SubjCode sąraše yra {len(train_subjcode_lst)} įrašai\")\n",
    "print(\"Mokymo imties SubjCode sąrašas įrašytas į:\", file_path)\n",
    "\n",
    "df_validation = df_list.loc[df_list['userId'].isin(list(validation['userID']))]\n",
    "print(\"\\ndf_validation:\")\n",
    "print_df_list(df_validation, False, True)\n",
    "validation_subjcode_lst = list(df_validation['SubjCode'])\n",
    "# print(validation_subjcode_lst)\n",
    "file_path = Path(rec_dir, 'validation_subjcode_lst.csv')\n",
    "np.savetxt(file_path, np.array(validation_subjcode_lst), delimiter=',', fmt='%d')\n",
    "print(f\"\\nValidacinės imties SubjCode sąraše yra {len(validation_subjcode_lst)} įrašai\")\n",
    "print(\"Validacinės imties SubjCode sąrašas įrašytas į:\", file_path)\n",
    "\n",
    "df_test = df_list.loc[df_list['userId'].isin(list(test['userID']))]\n",
    "print(\"\\ndf_test:\")\n",
    "print_df_list(df_test, False, True)\n",
    "test_subjcode_lst = list(df_test['SubjCode'])\n",
    "# print(test_subjcode_lst)\n",
    "file_path = Path(rec_dir, 'test_subjcode_lst.csv')\n",
    "np.savetxt(file_path, np.array(test_subjcode_lst), delimiter=',', fmt='%d')\n",
    "print(f\"\\nTestinės imties SubjCode sąraše yra {len(test_subjcode_lst)} įrašai\")\n",
    "print(\"Testinės imties SubjCode sąrašas įrašytas į:\", file_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fdd05f7b6e7f46fd1f1bbcbfdc9d8b4b1f98b078b306375c0cb77e6ad3f81a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ecg': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
