{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS in my system :  win32\n",
      "\n",
      "Skriptas skirtas zive EKG įrašuose esančių pūpsnių atributų sarašui all_beats_attr sukurti\n",
      "\n",
      "Bendras Zive duomenų aplankas:  D:\\DI\\Data\\MIT&ZIVE\\VU\n",
      "Zive EKG įrašų aplankas:  D:\\DI\\Data\\MIT&ZIVE\\VU\\DUOM_VU_TST\\records_npy\n",
      "EKG įrašų atributų sąrašas: list_npy.json\n",
      "Diskretizavimo dažnis:  200\n",
      "\n",
      "Pacientų įrašų kodų sąrašas:\n",
      " [10000, 10001, 10010, 10011, 10012, 10013, 10014, 10015, 10020, 10021, 10022, 10023, 10024, 10025, 10026, 10030, 10031, 10040, 10041, 10050, 10051, 10052, 10053, 10054, 10055, 10056, 10057, 10058, 10059, 10060, 10061, 10070, 10071, 10080, 10081, 10082, 10083, 10084, 10085, 10086, 10087, 10088, 10089, 10090, 10091, 10092, 10093, 10094, 10095, 10096, 10097, 10098, 10099, 10100, 10101, 10110, 10111]\n",
      "\n",
      "Anotacijų sąrašas:\n",
      " ['N', 'S', 'V', 'U']\n"
     ]
    }
   ],
   "source": [
    "# Skriptas pūpsnių atributų masyvui all_beats_attr sukurimui, o taip pat pacientų padalijimui\n",
    "# į dalis: train, validate, test, sukuria tų dalių SubjCode sąrašus ir įrašo juos į diską.\n",
    "#  \n",
    "# Atnaujintas variantas, po to, kaip padaryti pakeitimai failų varduose 2022 03 26\n",
    "#\n",
    "# Skriptas zive_creat_beats_attrib skirtas zive EKG įrašuose esančių pūpsnių atributų masyvui\n",
    "# all_beats_attr sukurti, kad būtų galima juos panaudoti sekų formavimui:\n",
    "# - atsikratome nepageidaujamų anotacijų: 'U'  ------- ///////////////////// pataisyti, neatsikratyti\n",
    "# - iš anotacijų suformuojame klasių numerius\n",
    "# - apskaičiuojami ir į atributus įrašomi RR intervalai: RRl, RRr. Atributų eilutėse,\n",
    "#  atitinkančios pirmą ir paskutinį pūpsnį, RRl ir RRr reikšmės lygios ???????????????????????????????????????\n",
    "#  sentinel = -1  - nereikia, skaičiuojama programiškai /////////////// ///////////////////////\n",
    "\n",
    "# Pacientų kodų sąrašas SubjCodes (userNr+file_name) paimamas iš list_npy.json, kurį\n",
    "# suformuoja zive_create_npy. Masyvas all_beats_attr įrašomas į failą all_beats_attr_z.csv.\n",
    "\n",
    "# Toliau pacientai sudalijami į dalis: train, validate, test. Šioms dalims sukūriami pacientų įrašų vardų SubjCode\n",
    "# sąrašai train_subjcode_lst, validate_subjcode_lst, test_subjcode_lst ir jie įrašomi į diską, kur paskui bus\n",
    "# naudojami indeksų generavimui.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from icecream import ic\n",
    "import json, time, sys\n",
    "\n",
    "from zive_util_vu import runtime, read_rec_attrib, split_SubjCode, get_annotations_table, print_annotations_table\n",
    "\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "my_os=sys.platform\n",
    "\n",
    "print(\"OS in my system : \",my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Pasiruošimas\n",
    "\n",
    "# //////////////// NURODOMI PARAMETRAI /////////////////////////////////////////////////////\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'D:\\DI\\Data\\MIT&ZIVE\\VU'   # variantas: Windows\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI/Data/MIT&ZIVE/VU'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "#  MIT2ZIVE duomenų aplankas\n",
    "db_folder = 'DUOM_VU_TST'\n",
    "\n",
    "# Aplankas su MIT2ZIVE EKG įrašais (.npy) ir anotacijomis (.json)\n",
    "rec_folder = 'records_npy'\n",
    "rec_list_npy = 'list_npy.json'\n",
    "train_beats_attr_fname ='all_beats_attr_z.csv'\n",
    "\n",
    "# Kas kiek išvedamas apdorotų duomenų skaičius\n",
    "show_period = 100\n",
    "\n",
    "# Failai pūpsnių klasių formavimui\n",
    "annot_grouping = {'N':'N', 'S':'S', 'V':'V', 'U':'U'}\n",
    "selected_beats = {'N':0, 'S':1, 'V':2, 'U':3}\n",
    "\n",
    "# ///////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Nuoroda į MIT2ZIVE duomenų aplanką\n",
    "db_path = Path(Duomenu_aplankas, db_folder)\n",
    "\n",
    "# Nuoroda į aplanką su MIT2ZIVE EKG įrašais (.npa) ir anotacijomis (.json)\n",
    "rec_dir = Path(db_path, rec_folder)\n",
    "\n",
    "# Nuskaitome failą info_create.json ir duomenų rinkinio parametrus\n",
    "file_path = Path(rec_dir,'info_create_z.json')\n",
    "with open(file_path) as json_file:\n",
    "    info_create = json.load(json_file)\n",
    "\n",
    "fs = info_create['fs'] # diskretizavimo dažnumas\n",
    "SubjCodes =  info_create['SubjCodes'] # pacientų įrašų sąrašas\n",
    "annot_list  = info_create['annot_list'] # anotacijų sąrašas\n",
    "# print(annot_list)\n",
    "\n",
    "# Susikuriame pagalbinį anotacijų žodyną - dictionary beats_annot\n",
    "nr_sequence = list(range(13))\n",
    "beats_annot = dict(zip(annot_list, nr_sequence))\n",
    "\n",
    "print(\"\\nSkriptas skirtas zive EKG įrašuose esančių pūpsnių atributų sarašui all_beats_attr sukurti\")\n",
    "print(\"\\nBendras Zive duomenų aplankas: \", Duomenu_aplankas)\n",
    "print(\"Zive EKG įrašų aplankas: \", rec_dir)\n",
    "print(\"EKG įrašų atributų sąrašas:\", rec_list_npy)\n",
    "\n",
    "print(\"Diskretizavimo dažnis: \", fs)\n",
    "print(\"\\nPacientų įrašų kodų sąrašas:\\n\",SubjCodes)\n",
    "print(\"\\nAnotacijų sąrašas:\\n\", annot_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "II-a dalis. SUDALIJAME PACIENTUS IR JŲ ĮRAŠUS Į TRAIN, VALIDATION IR TEST DALIS\n",
      "\n",
      "df_list:\n",
      "    SubjCode    file_name     N   S   V  U\n",
      "0      10000  1630673.825   762   4   0  0\n",
      "1      10001  1626941.468   859   2   0  0\n",
      "2      10010  1621694.321  6009   0   9  0\n",
      "3      10011  1626330.744   788   5   0  4\n",
      "4      10012  1626924.927   741   4   1  0\n",
      "5      10013  1626933.710   865   4   0  0\n",
      "6      10014  1626934.963   761   2   0  1\n",
      "7      10015  1626931.201   806   1   0  0\n",
      "8      10020  1625408.182  1166   2  17  0\n",
      "9      10021  1625402.027   748   4  13  0\n",
      "10     10022  1625400.796   802   2  14  0\n",
      "11     10023  1625403.256   808   0   9  0\n",
      "12     10024  1625405.103  1293   2   7  0\n",
      "13     10025  1625405.717  1285   1   7  0\n",
      "14     10026  1625403.874  1136   0   5  0\n",
      "15     10030  1630726.223   603   0   1  0\n",
      "16     10031  1630715.664   583   0   0  0\n",
      "17     10040  1630715.197   610   2   0  0\n",
      "18     10041  1630717.694   628   0   0  0\n",
      "19     10050  1630733.908   559   5   0  0\n",
      "20     10051  1630735.143   538   4   0  0\n",
      "21     10052  1630693.635   651   3   0  0\n",
      "22     10053  1630734.526   576   3   0  0\n",
      "23     10054  1630736.382   540   1   1  0\n",
      "24     10055  1630718.396   546   2   0  0\n",
      "25     10056  1630721.490   549   1   1  0\n",
      "26     10057  1630733.290   567   2   0  0\n",
      "27     10058  1630717.159   559   1   0  0\n",
      "28     10059  1630735.765   573   1   0  0\n",
      "29     10060  1630795.799   607   0   1  0\n",
      "30     10061  1630797.052   570   0   0  0\n",
      "31     10070  1631001.238   648   1   0  0\n",
      "32     10071  1630959.214   612   0   0  0\n",
      "33     10080  1630771.589   724   2  21  0\n",
      "34     10081  1630764.137   817   1  22  0\n",
      "35     10082  1630763.516   814   0  21  0\n",
      "36     10083  1630757.924   723  11   8  0\n",
      "37     10084  1630757.303   720   4  14  0\n",
      "38     10085  1630759.790   935   0  16  0\n",
      "39     10086  1630762.894   807   2  12  0\n",
      "40     10087  1630770.348   799   4  10  0\n",
      "41     10088  1630768.486   743   1  12  0\n",
      "42     10089  1630759.170   848   1   9  0\n",
      "43     10090  1631141.137   719  21   0  0\n",
      "44     10091  1631141.764   845  20   0  0\n",
      "45     10092  1631139.883  1019  13   0  5\n",
      "46     10093  1631076.545   897   8   0  0\n",
      "47     10094  1631135.494   644   5   0  0\n",
      "48     10095  1631057.738   767   5   0  0\n",
      "49     10096  1631075.918   896   5   0  0\n",
      "50     10097  1631137.375   678   5   0  0\n",
      "51     10098  1631136.121   666   5   0  0\n",
      "52     10099  1631131.731   653   4   0  0\n",
      "53     10100  1630869.824   748   1   0  0\n",
      "54     10101  1630859.890   770   0   0  0\n",
      "55     10110  1630890.629   600   0   4  0\n",
      "56     10111  1630879.362   755   0   0  0\n",
      "\n",
      "N:  47935  S:  177  V:  235  U:  10  total:  48357\n",
      "\n",
      "Viso pacientų: 12  EKG įrašų: 57\n",
      "\n",
      "Įrašų pasiskirstymas per pacientus\n",
      "                             N   S    V  U  count\n",
      "userId                                           \n",
      "6034c808d6c2740008035ede  1621   6    0  0      2\n",
      "60a917b354352a3df86dc1f2  9970  16   10  5      6\n",
      "60e1d80f93b55b41529e9eaa  7238  11   72  0      7\n",
      "613b1bc63d08d41309cdc8f1  1186   0    1  0      2\n",
      "613b1c013d08d44862cdc8f2  1238   2    0  0      2\n",
      "613b1c6f3d08d4370acdc8f3  5658  23    2  0     10\n",
      "613b1c9c3d08d43181cdc8f4  1177   0    1  0      2\n",
      "613b1cc33d08d4c0d5cdc8f5  1260   1    0  0      2\n",
      "613b1d0c3d08d413ffcdc8f6  7930  26  145  0     10\n",
      "613b1d673d08d4d1f3cdc8f8  7784  91    0  5     10\n",
      "613b1d903d08d4df57cdc8f9  1518   1    0  0      2\n",
      "613b1db23d08d4ea68cdc8fa  1355   0    4  0      2\n",
      "\n",
      "df_user_Id:\n",
      "                       userID  user_types\n",
      "0   6034c808d6c2740008035ede           1\n",
      "1   60a917b354352a3df86dc1f2           3\n",
      "2   60e1d80f93b55b41529e9eaa           3\n",
      "3   613b1bc63d08d41309cdc8f1           2\n",
      "4   613b1c013d08d44862cdc8f2           1\n",
      "5   613b1c6f3d08d4370acdc8f3           3\n",
      "6   613b1c9c3d08d43181cdc8f4           2\n",
      "7   613b1cc33d08d4c0d5cdc8f5           1\n",
      "8   613b1d0c3d08d413ffcdc8f6           3\n",
      "9   613b1d673d08d4d1f3cdc8f8           1\n",
      "10  613b1d903d08d4df57cdc8f9           1\n",
      "11  613b1db23d08d4ea68cdc8fa           2\n"
     ]
    }
   ],
   "source": [
    "# Here is a Python function that splits a Pandas dataframe into train, validation, and test dataframes\n",
    "#  with stratified sampling. It performs this split by calling scikit-learn's function train_test_split() twice.\n",
    "\n",
    "#  II-a dalis. SUDALIJAME PACIENTUS IR JŲ ĮRAŠUS Į TRAIN, VALIDATION IR TEST DALIS\n",
    "# Gausime df_train, df_validation, df_test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from zive_util_vu import get_annotations_distribution\n",
    "\n",
    "def print_df_list(df_list, flag1=True, flag2=True):\n",
    "    if flag1:\n",
    "        print(df_list[['SubjCode', 'file_name',  'N',   'S',    'V',   'U']])\n",
    "    if flag2:\n",
    "        sum = np.zeros(4,'int')\n",
    "        # print(' '*5, 'N',   'S',   'V',  'U')\n",
    "        sum[0] = df_list.iloc[:, 4].sum()\n",
    "        sum[1] = df_list.iloc[:, 5].sum()\n",
    "        sum[2] = df_list.iloc[:, 6].sum()\n",
    "        sum[3] = df_list.iloc[:, 7].sum()\n",
    "        total = sum.sum()\n",
    "        str =f\"\\nN:{int(sum[0]):>7}  S:{(int(sum[1])):5}  V:{int(sum[2]):5}  U:{int(sum[3]):4}  total:{total:>7}\" \n",
    "        print(str)\n",
    "\n",
    "\n",
    "def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n",
    "                                         frac_train=0.6, frac_val=0.15, frac_test=0.25,\n",
    "                                         random_state=None):\n",
    "    '''\n",
    "    https://localcoder.org/stratified-splitting-of-pandas-dataframe-into-training-validation-and-test-set\n",
    "\n",
    "    Splits a Pandas dataframe into three subsets (train, val, and test)\n",
    "    following fractional ratios provided by the user, where each subset is\n",
    "    stratified by the values in a specific column (that is, each subset has\n",
    "    the same relative frequency of the values in the column). It performs this\n",
    "    splitting by running train_test_split() twice.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_input : Pandas dataframe\n",
    "        Input dataframe to be split.\n",
    "    stratify_colname : str\n",
    "        The name of the column that will be used for stratification. Usually\n",
    "        this column would be for the label.\n",
    "    frac_train : float\n",
    "    frac_val   : float\n",
    "    frac_test  : float\n",
    "        The ratios with which the dataframe will be split into train, val, and\n",
    "        test data. The values should be expressed as float fractions and should\n",
    "        sum to 1.0.\n",
    "    random_state : int, None, or RandomStateInstance\n",
    "        Value to be passed to train_test_split().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_train, df_val, df_test :\n",
    "        Dataframes containing the three splits.\n",
    "    '''\n",
    "\n",
    "    if frac_train + frac_val + frac_test != 1.0:\n",
    "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n",
    "                         (frac_train, frac_val, frac_test))\n",
    "\n",
    "    if stratify_colname not in df_input.columns:\n",
    "        raise ValueError('%s is not a column in the dataframe' % (stratify_colname))\n",
    "\n",
    "    X = df_input # Contains all columns.\n",
    "    y = df_input[[stratify_colname]] # Dataframe of just the column on which to stratify.\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp, y_train, y_temp = train_test_split(X,\n",
    "                                                          y,\n",
    "                                                          stratify=y,\n",
    "                                                          test_size=(1.0 - frac_train),\n",
    "                                                          random_state=random_state)\n",
    "\n",
    "    # Split the temp dataframe into val and test dataframes.\n",
    "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
    "    df_val, df_test, y_val, y_test = train_test_split(df_temp,\n",
    "                                                      y_temp,\n",
    "                                                      stratify=y_temp,\n",
    "                                                      test_size=relative_frac_test,\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1000, \"display.max_columns\", 19)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"\\nII-a dalis. SUDALIJAME PACIENTUS IR JŲ ĮRAŠUS Į TRAIN, VALIDATION IR TEST DALIS\")\n",
    "\n",
    "all_beats_attr = pd.DataFrame(columns= ['userNr', 'file_name', 'sample', 'symbol'])\n",
    "\n",
    "# Surenkame informaciją apie pacientus\n",
    "# Nuskaitomas įrašų sąrašas, suformuojamas atitinkamas dataframe df_list\n",
    "file_path = Path(rec_dir, rec_list_npy)\n",
    "with open(file_path,'r', encoding='UTF-8', errors = 'ignore') as f:\n",
    "    data = json.loads(f.read())\n",
    "df_list = pd.json_normalize(data, record_path =['data'])\n",
    "print(\"\\ndf_list:\")\n",
    "print_df_list(df_list)\n",
    "\n",
    "# Susirandame anotacijų pasiskirstymą per įrašus\n",
    "annot_list = ['N', 'S', 'V', 'U']\n",
    "# Susikuriame pagalbinį anotacijų žodyną - dictionary beats_annot\n",
    "nr_sequence = list(range(len(annot_list)))\n",
    "beats_annot = dict(zip(annot_list, nr_sequence))\n",
    "# print(beats_annot)\n",
    "\n",
    "# labels_rec_all = get_annotations_distribution(df_list, rec_dir, beats_annot)\n",
    "# print(\"\\nlabels_rec_all:\")\n",
    "# print(labels_rec_all)\n",
    "# print(labels_rec_all.dtypes)\n",
    "\n",
    "# Susirandame anotacijų pasiskirstymą per pacientus ir pacientų skaičių\n",
    "df_sum = df_list.groupby(['userId'],sort = False).sum()\n",
    "# print(df_sum)\n",
    "\n",
    "# https://sparkbyexamples.com/pandas/pandas-groupby-sum-examples/\n",
    "count = df_list['userId'].value_counts()\n",
    "print(f'\\nViso pacientų: {len(count)}  EKG įrašų: {len(df_list)}')\n",
    "print(f'\\nĮrašų pasiskirstymas per pacientus')\n",
    "count = count.rename(\"count\")\n",
    "frames = [df_sum, count]\n",
    "result = pd.concat(frames, axis = 1)\n",
    "result.index.rename ('userId', inplace= True)\n",
    "# https://www.shanelynn.ie/pandas-drop-delete-dataframe-rows-columns/\n",
    "\n",
    "print(result[['N',   'S',    'V',   'U', 'count']])\n",
    "\n",
    "# filepath = Path(db_path, 'result.csv') \n",
    "# result.to_csv(filepath)\n",
    "# print(f'Failų sąrašas ir rezultatai įrašyti į:  {filepath}')    \n",
    "\n",
    "# Susumuojamos anotacijos\n",
    "# suma = labels_rec_all.iloc[:,3:8].sum()\n",
    "# print('\\n',' '*18, 'sum: ',str(suma.tolist())[1:-1])\n",
    "# total = suma.sum()\n",
    "# print(' '*17, 'total: ', total)\n",
    "\n",
    "# Išplečiame freimą result iki pozymio user_type, kurį naudosime kaip stratify splitinant į train, test\n",
    "\n",
    "# Nustatome user_type pagal bendrus 'S' ir 'V' skaičius per visus paciento įrašus \n",
    "# user_type == 0, jei  bendras skaičius 'S'==0 ir bendras skaičius 'V'==0\n",
    "# user_type == 1, jei  bendras skaičius 'S'> 0 ir bendras skaičius 'V'==0\n",
    "# user_type == 2, jei  bendras skaičius 'S'==0 ir bendras skaičius 'V'> 0\n",
    "# user_type == 3, jei  bendras skaičius 'S'> 0 ir bendras skaičius 'V'>0\n",
    "\n",
    "result = result.reset_index()\n",
    "user_types = np.zeros(len(result), dtype = int )\n",
    "userIds = []\n",
    "for i, row in result.iterrows():\n",
    "    # print(row)\n",
    "    userIds.append(row['userId'])\n",
    "    if ((row['S'] == 0) & (row['V'] == 0)):\n",
    "        user_types[i] = 0\n",
    "    if ((row['S'] > 0) & (row['V'] == 0)):\n",
    "        user_types[i] = 1\n",
    "    if ((row['S'] == 0) & (row['V'] > 0)):\n",
    "        user_types[i] = 2\n",
    "    if ((row['S'] > 0) & (row['V'] > 0)):\n",
    "        user_types[i] = 3\n",
    "\n",
    "# print(userIds)\n",
    "\n",
    "# df_userId = pd.DataFrame(columns = ['userId', 'user_types'])\n",
    "df_userId = pd.DataFrame()\n",
    "df_userId['userID'] = userIds\n",
    "df_userId['user_types'] = user_types\n",
    "\n",
    "print(\"\\ndf_user_Id:\\n\", df_userId)\n",
    "\n",
    "# print(user_types)\n",
    "# result['user_type'] = user_types\n",
    "# print(\"\\nresult\\n\", result)\n",
    "\n",
    "# Sudalijame duomenis į train, test\n",
    "\n",
    "# train, test = train_test_split(userIds, test_size=0.3,stratify=user_types, random_state=42)\n",
    "# print(\"\\ntrain\\n\", train)\n",
    "# print(\"\\nvalidate\\n\", test)\n",
    "\n",
    "# train, test = train_test_split(userIds, test_size=0.3,stratify=user_types, random_state=42)\n",
    "\n",
    "frac_train=0.35\n",
    "frac_val=0.35\n",
    "frac_test=0.3\n",
    "train, validation, test = split_stratified_into_train_val_test(df_userId, stratify_colname='user_types',\n",
    "                                        frac_train=frac_train, frac_val=frac_val, frac_test=frac_test, random_state=None)\n",
    "\n",
    "# print(\"\\ntrain\\n\", train)\n",
    "# print(\"\\nvalidate\\n\", test)\n",
    "# print(\"\\ntest\\n\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frac_train: 0.35, frac_val: 0.35, frac_test: 0.3\n",
      "\n",
      "df_train:\n",
      "\n",
      "N:  17637  S:  103  V:   76  U:   5  total:  17821\n",
      "\n",
      "Mokymo imties SubjCode sąraše yra 21 įrašai\n",
      "Mokymo imties SubjCode sąrašas įrašytas į: D:\\DI\\Data\\MIT&ZIVE\\VU\\DUOM_VU_TST\\records_npy\\train_subjcode_lst.csv\n",
      "\n",
      "df_validation:\n",
      "\n",
      "N:  12246  S:   33  V:  146  U:   0  total:  12425\n",
      "\n",
      "Validacinės imties SubjCode sąraše yra 16 įrašai\n",
      "Validacinės imties SubjCode sąrašas įrašytas į: D:\\DI\\Data\\MIT&ZIVE\\VU\\DUOM_VU_TST\\records_npy\\validation_subjcode_lst.csv\n",
      "\n",
      "df_test:\n",
      "\n",
      "N:  18052  S:   41  V:   13  U:   5  total:  18111\n",
      "\n",
      "Testinės imties SubjCode sąraše yra 20 įrašai\n",
      "Testinės imties SubjCode sąrašas įrašytas į: D:\\DI\\Data\\MIT&ZIVE\\VU\\DUOM_VU_TST\\records_npy\\test_subjcode_lst.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"frac_train: {frac_train}, frac_val: {frac_val}, frac_test: {frac_test}\")\n",
    "df_train = df_list.loc[df_list['userId'].isin(list(train['userID']))]\n",
    "print(\"\\ndf_train:\")\n",
    "print_df_list(df_train, False, True)\n",
    "train_subjcode_lst = list(df_train['SubjCode'])\n",
    "print(train_subjcode_lst)\n",
    "file_path = Path(rec_dir, 'train_subjcode_lst.csv')\n",
    "np.savetxt(file_path, np.array(train_subjcode_lst), delimiter=',', fmt='%d')\n",
    "print(f\"\\nMokymo imties SubjCode sąraše yra {len(train_subjcode_lst)} įrašai\")\n",
    "print(\"Mokymo imties SubjCode sąrašas įrašytas į:\", file_path)\n",
    "\n",
    "df_validation = df_list.loc[df_list['userId'].isin(list(validation['userID']))]\n",
    "print(\"\\ndf_validation:\")\n",
    "print_df_list(df_validation, False, True)\n",
    "validation_subjcode_lst = list(df_validation['SubjCode'])\n",
    "# print(validation_subjcode_lst)\n",
    "file_path = Path(rec_dir, 'validation_subjcode_lst.csv')\n",
    "np.savetxt(file_path, np.array(validation_subjcode_lst), delimiter=',', fmt='%d')\n",
    "print(f\"\\nValidacinės imties SubjCode sąraše yra {len(validation_subjcode_lst)} įrašai\")\n",
    "print(\"Validacinės imties SubjCode sąrašas įrašytas į:\", file_path)\n",
    "\n",
    "\n",
    "df_test = df_list.loc[df_list['userId'].isin(list(test['userID']))]\n",
    "print(\"\\ndf_test:\")\n",
    "print_df_list(df_test, False, True)\n",
    "test_subjcode_lst = list(df_test['SubjCode'])\n",
    "# print(test_subjcode_lst)\n",
    "file_path = Path(rec_dir, 'test_subjcode_lst.csv')\n",
    "np.savetxt(file_path, np.array(test_subjcode_lst), delimiter=',', fmt='%d')\n",
    "print(f\"\\nTestinės imties SubjCode sąraše yra {len(test_subjcode_lst)} įrašai\")\n",
    "print(\"Testinės imties SubjCode sąrašas įrašytas į:\", file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EKG įrašams suformuojamas pūpsnių atributų freimas ir įrašomas į diską\n",
      "\n",
      "ECG įrašas: 10000\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10001\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10010\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 \n",
      "ECG įrašas: 10011\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10012\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10013\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10014\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10015\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10020\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 \n",
      "ECG įrašas: 10021\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10022\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10023\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10024\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 \n",
      "ECG įrašas: 10025\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 1200 \n",
      "ECG įrašas: 10026\n",
      "100 200 300 400 500 600 700 800 900 1000 1100 \n",
      "ECG įrašas: 10030\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10031\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10040\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10041\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10050\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10051\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10052\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10053\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10054\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10055\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10056\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10057\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10058\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10059\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10060\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10061\n",
      "100 200 300 400 500 \n",
      "ECG įrašas: 10070\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10071\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10080\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10081\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10082\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10083\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10084\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10085\n",
      "100 200 300 400 500 600 700 800 900 \n",
      "ECG įrašas: 10086\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10087\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10088\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10089\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10090\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10091\n",
      "100 200 300 400 500 600 700 800 \n",
      "ECG įrašas: 10092\n",
      "100 200 300 400 500 600 700 800 900 1000 \n",
      "ECG įrašas: 10093\n",
      "100 200 300 400 500 600 700 800 900 \n",
      "ECG įrašas: 10094\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10095\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10096\n",
      "100 200 300 400 500 600 700 800 900 \n",
      "ECG įrašas: 10097\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10098\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10099\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10100\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10101\n",
      "100 200 300 400 500 600 700 \n",
      "ECG įrašas: 10110\n",
      "100 200 300 400 500 600 \n",
      "ECG įrašas: 10111\n",
      "100 200 300 400 500 600 700 \n",
      "\n",
      "\n",
      "Visi duomenys\n",
      "\n",
      "symbol         N    S   U    V    All\n",
      "SubjCodes                            \n",
      "10000        762    4   0    0    766\n",
      "10001        859    2   0    0    861\n",
      "10010       6009    0   0    9   6018\n",
      "10011        788    5   4    0    797\n",
      "10012        741    4   0    1    746\n",
      "10013        865    4   0    0    869\n",
      "10014        761    2   1    0    764\n",
      "10015        806    1   0    0    807\n",
      "10020       1166    2   0   17   1185\n",
      "10021        748    4   0   13    765\n",
      "10022        802    2   0   14    818\n",
      "10023        808    0   0    9    817\n",
      "10024       1293    2   0    7   1302\n",
      "10025       1285    1   0    7   1293\n",
      "10026       1136    0   0    5   1141\n",
      "10030        603    0   0    1    604\n",
      "10031        583    0   0    0    583\n",
      "10040        610    2   0    0    612\n",
      "10041        628    0   0    0    628\n",
      "10050        559    5   0    0    564\n",
      "10051        538    4   0    0    542\n",
      "10052        651    3   0    0    654\n",
      "10053        576    3   0    0    579\n",
      "10054        540    1   0    1    542\n",
      "10055        546    2   0    0    548\n",
      "10056        549    1   0    1    551\n",
      "10057        567    2   0    0    569\n",
      "10058        559    1   0    0    560\n",
      "10059        573    1   0    0    574\n",
      "10060        607    0   0    1    608\n",
      "10061        570    0   0    0    570\n",
      "10070        648    1   0    0    649\n",
      "10071        612    0   0    0    612\n",
      "10080        724    2   0   21    747\n",
      "10081        817    1   0   22    840\n",
      "10082        814    0   0   21    835\n",
      "10083        723   11   0    8    742\n",
      "10084        720    4   0   14    738\n",
      "10085        935    0   0   16    951\n",
      "10086        807    2   0   12    821\n",
      "10087        799    4   0   10    813\n",
      "10088        743    1   0   12    756\n",
      "10089        848    1   0    9    858\n",
      "10090        719   21   0    0    740\n",
      "10091        845   20   0    0    865\n",
      "10092       1019   13   5    0   1037\n",
      "10093        897    8   0    0    905\n",
      "10094        644    5   0    0    649\n",
      "10095        767    5   0    0    772\n",
      "10096        896    5   0    0    901\n",
      "10097        678    5   0    0    683\n",
      "10098        666    5   0    0    671\n",
      "10099        653    4   0    0    657\n",
      "10100        748    1   0    0    749\n",
      "10101        770    0   0    0    770\n",
      "10110        600    0   0    4    604\n",
      "10111        755    0   0    0    755\n",
      "All        47935  177  10  235  48357\n",
      "Total:  96714\n",
      "\n",
      "Atributų freimas įrašytas: į  D:\\DI\\Data\\MIT&ZIVE\\VU\\DUOM_VU_TST\\records_npy\\all_beats_attr_z.csv \n",
      "\n",
      "\n",
      "\n",
      "Runtime: 00:01:11\n",
      "\n",
      "Pabaiga.............\n"
     ]
    }
   ],
   "source": [
    "# III-a dalis. zive EKG įrašai analizuojami, formuojamas freimas all_beats_attr ir  įrašomas į diską. \n",
    "\n",
    "# from zive_util import print_annotations_table\n",
    "\n",
    "print(\"\\nEKG įrašams suformuojamas pūpsnių atributų freimas ir įrašomas į diską\")\n",
    "\n",
    "# Pacientų įrašų sąrašas bandymams:\n",
    "# SubjCodes = ['10001']\n",
    "\n",
    "\n",
    "# Sukūriame masyvą sekų atributų sąrašo kaupimui\n",
    "all_beats_attr = pd.DataFrame({'userNr': pd.Series(dtype='int'),\n",
    "                   'recordingNr': pd.Series(dtype='int'),\n",
    "                   'sample': pd.Series(dtype='int'),\n",
    "                   'symbol': pd.Series(dtype='str')})\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# CIKLAS PER PACIENTŲ ĮRAŠUS\n",
    "\n",
    "# for SubjCode in SubjCodes:\n",
    "for idx, row in df_list.iterrows():    \n",
    "    SubjCode = row['SubjCode']\n",
    "    print(\"\\nECG įrašas:\", SubjCode)\n",
    "    \n",
    "    # Paciento anotacijų ir EKG įrašų nuskaitymas, sekų išpjovimas ir įrašymas, sekų atributų formavimas\n",
    "\n",
    "    # Nuskaitome paciento anotacijas ir jų indeksus\n",
    "    atr_sample, atr_symbol = read_rec_attrib(rec_dir, SubjCode)\n",
    "\n",
    "    subject_labels = []\n",
    "    beat_nr = 0\n",
    "    icycle = 0\n",
    "\n",
    "    # Ciklas per visas paciento įrašo anotacijas (simbolius) ir jų vietas (i_sample)\n",
    "    for i, i_sample in enumerate(atr_sample):\n",
    "    \n",
    "        icycle +=1\n",
    "        if (icycle%show_period == 0):\n",
    "            print(icycle, end =' ') \n",
    "\n",
    "        # Formuojame pūpsnio atributus\n",
    "        userNr, recordingNr = split_SubjCode(SubjCode)\n",
    "\n",
    "        beats_attr = {'userNr':int(userNr), 'recordingNr':int(recordingNr), 'sample':int(i_sample), 'symbol':str(atr_symbol[i])}\n",
    "        \n",
    "        # Senas variantas\n",
    "        # train_beats_attr = train_beats_attr.append(beats_attr, ignore_index=True)\n",
    "\n",
    "        # Variantas su concat\n",
    "        df_new_row = pd.DataFrame([beats_attr])\n",
    "        all_beats_attr = pd.concat([all_beats_attr, df_new_row])\n",
    "\n",
    "        # Galima perrašyti ir kitaip, naudojant pd.DataFrame.from_records\n",
    "        # all_beats_attr = pd.concat([all_beats_attr, pd.DataFrame.from_records([beats_attr])])\n",
    "\n",
    "        beat_nr +=1\n",
    "\n",
    "\n",
    "# Ciklo per pacientų įrašus pabaiga\n",
    "\n",
    "# Atsikratome nepageidaujamų anotacijų: 'U'\n",
    "# index_names = train_beats_attr[train_beats_attr['symbol'].isin(['U'])].index\n",
    "# train_beats_attr.drop(index_names, inplace = True)\n",
    "# print(train_beats_attr.info())\n",
    "\n",
    "# Pernumeruojame indeksus, kad būtų nuo 0 iš eilės\n",
    "all_beats_attr.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Iš anotacijų suformuojame klasių numerius ir pridedame, kaip naują stulpelį\n",
    "annot_labels = {key:selected_beats[value] for key, value in annot_grouping.items()}\n",
    "labels_from_annot = all_beats_attr['symbol'].replace(annot_labels, inplace=False)\n",
    "all_beats_attr['label'] = labels_from_annot\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\nVisi duomenys\\n\")\n",
    "labels_table, labels_sums = get_annotations_table(all_beats_attr)\n",
    "print_annotations_table(labels_table, labels_sums, Flag1=True, Flag2=False)\n",
    "\n",
    "# Įrašome sekos atributų masyvą į seq_dir aplanką\n",
    "file_path = Path(rec_dir, train_beats_attr_fname)\n",
    "all_beats_attr.index.name = \"id\"\n",
    "\n",
    "all_beats_attr.to_csv(file_path, )\n",
    "print(\"\\nAtributų freimas įrašytas: į \", file_path, \"\\n\" )\n",
    "\n",
    "end_time = time.time()\n",
    "print('\\n')\n",
    "runtime(end_time-start_time)\n",
    "\n",
    "print(\"\\nPabaiga.............\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fdd05f7b6e7f46fd1f1bbcbfdc9d8b4b1f98b078b306375c0cb77e6ad3f81a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ecg': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
