{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skriptas Zive klasifikavimo rezultatų failo analizei\n",
      "OS in my system :  win32\n",
      "\n",
      "Bendras duomenų aplankas:  D:\\DI\\Data\\MIT&ZIVE\\VU\n",
      "Zive duomenų aplankas:  DUOM_VU\n",
      "Aplankas su resultatais  D:\\DI\\Data\\MIT&ZIVE\\VU\\DUOM_VU\\test_results\\test\n",
      "Pūpsnių atributų failas: all_beats_attr_z.csv\n",
      "Klasifikavimo schema: {'N': 0, 'S': 1, 'V': 2}\n",
      "Klasių skaičius: 3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variantas:  vieno įrašo detalus testavimas \n",
    "\n",
    "# Atnaujintas variantas, po to, kaip padaryti pakeitimai failų varduose 2022 03 26\n",
    "# Šis variantas pritaikytas npy formato zive įrašams, kuriems pakeistas, lyginant su \n",
    "# originaliais įrašais, failo vardas iš `file_name` į `SubjCode`, pridedant `userNr`\n",
    "# prie `file_name`. \n",
    "#\n",
    "# Skriptas zive EKG pūpsnių CNN VU klasifikatoriaus testavimui ir tikslumo įvertinimui, funkcijos \n",
    "# paimamos iš aplanko zive_cnn_fda_vu_v1.py, modelis iš model_cnn_fda_vu_v1, testuojami duomenys\n",
    "# iš db_folder įrašų saugyklos, jame yra ir failas all_beats_attr. \n",
    "\n",
    "# Testavimui imami įrašai iš sąrašo SubjCodes, kuris arba paimamas if failo info_create.json,\n",
    "# arba iš mokymo, validavimo, testavimo sarašų, pvz. train_subjcode_lst.csv. Visiems įrašams iš šių\n",
    "# sąrašų egzistuoja informacija apie pūpsnius faile all_beats_attr.\n",
    " \n",
    "# Skripte yra galimybė išvesti ekstrasistolių vietas įraše.\n",
    "# Dirbant su daug įrašų reiktų užblokuoti: classification = []  # Užblokuota\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys, json\n",
    "from pathlib import Path\n",
    "from icecream import ic\n",
    "\n",
    "# from zive_util_vu import cm2df, show_confusion_matrix \n",
    "# from zive_util_vu import create_dir, create_subdir, get_rev_dictionary\n",
    "# from zive_util_vu import runtime, split_SubjCode\n",
    "# from zive_util_vu import get_freq_unique_values\n",
    "\n",
    "# from zive_util_vu import get_beat_attributes\n",
    "# from zive_util_vu import get_userId, read_rec, get_filename \n",
    "# from zive_util_vu import confusion_matrix_modified, zive_read_df_rpeaks\n",
    "\n",
    "# from zive_cnn_fda_vu_v1 import predict_cnn_fda_vu_v1, zive_read_file_1ch\n",
    "# Pastaba: zive_read_file_1ch importuoju iš zive_cnn_fda_vu_v1, nors ji yra ir zive_util_vu.py\n",
    "# tam, kad atskirti funkcijas, kurios importuojamos skripte zive analysis, nuo tų funkcijų,\n",
    "# kurios reikalingos tik zive_accuracy_cnn_vu_v1 ir v2. \n",
    "\n",
    "\n",
    "print(\"Skriptas Zive klasifikavimo rezultatų failo analizei\")\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "my_os=sys.platform\n",
    "print(\"OS in my system : \",my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Pasiruošimas\n",
    "\n",
    "# //////////////// NURODOMI PARAMETRAI /////////////////////////////////////////////////////\n",
    "\n",
    "# Bendras duomenų aplankas, kuriame patalpintas subfolderis name_db\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'D:\\DI\\Data\\MIT&ZIVE\\VU'   # variantas: Windows\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI/Data/MIT&ZIVE/VU'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# Vietinės talpyklos aplankas ir pūpsnių atributų failas\n",
    "db_folder = 'DUOM_VU'\n",
    "\n",
    "# Vietinės talpyklos aplankas ir pūpsnių atributų failas\n",
    "all_beats_attr_fname = 'all_beats_attr_z.csv'\n",
    "\n",
    "# Failai pūpsnių klasių formavimui\n",
    "selected_beats = {'N':0, 'S':1, 'V':2}\n",
    "all_beats =  {'N':0, 'S':1, 'V':2, 'U':3}  \n",
    "\n",
    "# /////////////////////////////////////////////////////////////////\n",
    "\n",
    "#  Nuoroda į aplanką su MIT2ZIVE duomenų rinkiniu\n",
    "db_path = Path(Duomenu_aplankas, db_folder)\n",
    "\n",
    "# Nuoroda į aplanką su EKG įrašais (.npy) ir anotacijomis (.json)\n",
    "res_dir = Path(db_path, 'test_results', 'test')\n",
    "\n",
    "# Išvedame parametrus\n",
    "print(\"\\nBendras duomenų aplankas: \", Duomenu_aplankas)\n",
    "print(\"Zive duomenų aplankas: \", db_folder)\n",
    "print(\"Aplankas su resultatais \", res_dir)\n",
    "print(\"Pūpsnių atributų failas:\", all_beats_attr_fname)\n",
    "print('Klasifikavimo schema:', selected_beats)\n",
    "print('Klasių skaičius:', len(selected_beats))\n",
    "\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24924\\1343564958.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mdf_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzive_read_df_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'automatic_classification'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# with open(file_path,'r') as f:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ecg_lnx\\lib\\pathlib.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m             \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWindowsPath\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nt'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mPosixPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1027\u001b[1;33m         \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_parts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1028\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m             raise NotImplementedError(\"cannot instantiate %r on your system\"\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ecg_lnx\\lib\\pathlib.py\u001b[0m in \u001b[0;36m_from_parts\u001b[1;34m(cls, args, init)\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;31m# right flavour.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mdrv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ecg_lnx\\lib\\pathlib.py\u001b[0m in \u001b[0;36m_parse_args\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[0mparts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                 \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m                     \u001b[1;31m# Force-cast str subclasses to str (issue #21127)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not float"
     ]
    }
   ],
   "source": [
    "def zive_read_df_data(file_path, name):\n",
    "    df_data = pd.DataFrame()\n",
    "    path = Path(file_path)\n",
    "    # https://www.askpython.com/python-modules/check-if-file-exists-in-python\n",
    "    if (path.exists()):\n",
    "        with open(file_path,'r', encoding='UTF-8', errors = 'ignore') as f:\n",
    "            data = json.loads(f.read())\n",
    "        df_data = pd.json_normalize(data, record_path =[name])\n",
    "    return df_data\n",
    "\n",
    "filenames = [1625402.027]\n",
    "\n",
    "for file_name in filenames:\n",
    "    file_path = Path(res_dir, file_name)\n",
    "    df_data = zive_read_df_data(file_path, 'automatic_classification')\n",
    "    # with open(file_path,'r') as f:\n",
    "        # data = json.loads(f.read())\n",
    "    print(df_data)    \n",
    "    # df_rpeaks = pd.json_normalize(data, record_path =['automatic_classification'])\n",
    "\n",
    "# print(df_rpeaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASIRUOŠIMAS\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 6000, \"display.max_columns\",200)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Naudojamų požymių sąrašas\n",
    "\n",
    "               \n",
    "print(\"\\nAtliekama pūpsnių pacientų įrašuose klasifikacija\")\n",
    "\n",
    "# Pacientų įrašų sąrašas testavimui\n",
    "file_path = 'testinis_sarasas.csv'\n",
    "SubjCodes = [10021, 10022, 10083, 10091] #Testavimui, iš mokymo imties\n",
    "# SubjCodes = [10021] #Testavimuas pacientų įrašų sąrašas\n",
    "\n",
    "print(\"Klasifikuojamų įrašų sąrašas:\", SubjCodes)\n",
    "print(f\"Sąrašas nuskaitytas iš: {file_path}\")\n",
    "\n",
    "# Kas kiek išvedamas apdorotų sekų skaičius\n",
    "show_period = 100\n",
    "\n",
    "# Klasių simbolinių vardų sąrašas ir klasių skaičius\n",
    "class_names = list(selected_beats.keys()) \n",
    "n_classes = len(selected_beats)\n",
    "# print(class_names)\n",
    "\n",
    "# Nuskaitome pūpsnių atributų masyvą\n",
    "file_path = Path(rec_dir, all_beats_attr_fname)\n",
    "all_beats_attr = pd.read_csv(file_path, index_col=0, dtype = {'userNr': int, 'recordingNr': int,\n",
    "                                                             'sample': int, 'symbol': str, 'label': int})\n",
    "all_beat_indices = all_beats_attr.index\n",
    "\n",
    "index_start = 0\n",
    "# Sukūriame masyvą, į kurį sudėsime visų įrašų pūpsnių anotuotus ir automatiškai surastus klasių numerius\n",
    "validation_set_stats = pd.DataFrame(columns=['idx', 'test_label', 'pred_label', 'SubjCode'])\n",
    "\n",
    "start_time = time.time()\n",
    "# Ciklas per pacientų įrašus\n",
    "for SubjCode in SubjCodes:\n",
    "    \n",
    "    # Nuskaitome EKG įrašą (npy formatu)\n",
    "    sign_raw = read_rec(rec_dir, SubjCode)\n",
    "    signal_length = sign_raw.shape[0]\n",
    "    signal = sign_raw\n",
    "\n",
    "    # Surandame ir išvedame įrašo atributus\n",
    "    print(\"\\nZive įrašas:\")\n",
    "    file_name = get_filename(rec_dir, SubjCode)\n",
    "    userNr, recNr = split_SubjCode(SubjCode)\n",
    "    print(f\"SubjCode: {SubjCode} userNr: {userNr:>2} file_name: {file_name:>2} signal_length: {signal_length}\")\n",
    "    \n",
    "    filepath = Path(rec_dir, str(SubjCode) + '.json')\n",
    "    with open(filepath,'r', encoding='UTF-8', errors = 'ignore') as f:\n",
    "        data = json.loads(f.read())\n",
    "    userId = data['userId']\n",
    "    recordingId = data['recordingId']\n",
    "    print(f\"userId: {userId}  recordingId: {recordingId}\")\n",
    "\n",
    "    # Filtruojame signalą\n",
    "    # signal = signal_filter(signal=sign_raw, sampling_rate=200, lowcut=0.2, method=\"butterworth\", order=5)\n",
    "\n",
    "    # Nuskaitome paciento anotacijas ir jų indeksus\n",
    "    df_rpeaks = zive_read_df_rpeaks(rec_dir, str(SubjCode))\n",
    "    atr_sample = df_rpeaks['sampleIndex'].to_numpy()\n",
    "    atr_symbol = df_rpeaks['annotationValue'].to_numpy()\n",
    "\n",
    "    # SUFORMUOJAME EKG ĮRAŠUI TESTINĮ ir PRISKIRTŲ KLASIŲ NUMERIŲ MASYVUS\n",
    "\n",
    "    # Jei pasitaiko symbol 'U' arba 'F', pūpsniui suteikiame klasę 3, kurią vėliau apvalysime  \n",
    "    test_labels = np.array([all_beats[symbol] for symbol in atr_symbol])\n",
    "\n",
    "    (unique, counts) = np.unique(atr_symbol, return_counts=True)\n",
    "    total = counts.sum()\n",
    "    print(\"test_symbols: \", unique, counts, total)\n",
    "\n",
    "    (unique, counts) = np.unique(test_labels, return_counts=True)\n",
    "    total = counts.sum()\n",
    "    print(\"test_labels: \", unique, counts, total)\n",
    "   \n",
    "    pred_labels = predict_cnn_fda_vu_v1(signal, atr_sample, model_dir)\n",
    "    # pred_labels turi būti tokio pat ilgio, kaip ir test_labels, praleisti (šiuo atveju pirmas\n",
    "    # ir paskutinis pūpsnys), o taip pat pakliuvęs į ommited sritį, pažymimi klase 3\n",
    "    if (len(test_labels) != len(pred_labels)):\n",
    "        raise Exception(f\"Klaida! SubjCode: {SubjCode}. Nesutampa test_labels ir pred_labels ilgiai\")     \n",
    "\n",
    "    (unique, counts) = np.unique(pred_labels, return_counts=True)\n",
    "    total = counts.sum()\n",
    "    print(\"pred_labels: \",unique, counts, total)\n",
    "\n",
    "    symbol_dict = dict(zip(all_beats.values(), all_beats.keys()))\n",
    "    print(symbol_dict)\n",
    "    # Surandame vietas su ekstrasistolemis ir išvedame jų sąrašą vizualiniam įvertinimui. \n",
    "    classification=[]\n",
    "    for i, i_sample in enumerate(atr_sample):\n",
    "        if ((pred_labels[i] != 0) or test_labels[i] != 0):\n",
    "            classification.append({'sample':i_sample, 'annot':symbol_dict[test_labels[i]], 'pred':symbol_dict[pred_labels[i]]})\n",
    "\n",
    "    # Vietų sąrašas išvedamas\n",
    "    # Dirbant su daug įrašų sąrašo išvedimą reikia užblokuoti !!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    # classification = []  # Užblokuota\n",
    "    if (classification):\n",
    "        tot = 0\n",
    "        tot_U = 0\n",
    "        for row in classification:\n",
    "            print(f\"sample: {row['sample']:>7}   annot_label: {row['annot']:>2}   pred_label: {row['pred']:>2}\")\n",
    "            if (row['pred'] != 'U'):\n",
    "                tot += 1\n",
    "            else:\n",
    "                tot_U +=1     \n",
    "\n",
    "    print(f\"rpeaks total: {len(atr_sample)}\")\n",
    "    print(f\"excluded rpeaks ('U'): {tot_U}\")\n",
    "    print(f\"classified rpeaks: {len(atr_sample) - tot_U}\")\n",
    "    print(f\"automaticRpeakAnnotations: {tot}\")\n",
    "\n",
    "    # SUFORMUOJAME FREIMĄ validation_set_stats SU PŪPSNIŲ KLASIŲ ANOTUOTAIS IR AUTOMATIŠKAI \n",
    "    # SURASTAIS KLASIŲ NUMERIAIS, IŠMETANT KLASES SU NUMERIU = 3\n",
    "\n",
    "    # Surandame pradinį SubjCode įrašo indeksą faile all_beats_attr\n",
    "    selected_ind = all_beat_indices[(all_beats_attr['userNr']==userNr) & (all_beats_attr['recordingNr']==recNr)]\n",
    "    # print(f\"SubjCode: {SubjCode}  first elem: {selected_ind[0]} last elem: {selected_ind[-1]}  tot: {len(selected_ind)}\")\n",
    "    index_start = selected_ind[0]\n",
    "    # print('\\nSubjCode:',SubjCode, 'index_start:', index_start)   \n",
    "\n",
    "    #  Praleisdami indeksą, jei masyvuose test_labels ir pred_labels yra reikšmė == 3,\n",
    "    # suformuojame klasifikuotinų pūpsnių indeksų sąrašą\n",
    "    for idx in range(len(atr_sample)):\n",
    "        flag = (test_labels[idx] == 3) or (pred_labels[idx] == 3)\n",
    "        if (flag == False):\n",
    "            # Dėmesio: ?????????????????????????????????????????????\n",
    "            # taisytina vieta, bus problemų su pandas 1.4.1\n",
    "            validation_set_stats = validation_set_stats.append({'idx':index_start+idx, \n",
    "            'test_label':test_labels[idx],'pred_label':pred_labels[idx], 'SubjCode': SubjCode}, ignore_index=True)\n",
    "\n",
    "            # validation_set_stats = validation_set_stats.append({'idx':index_start+idx, \n",
    "            # 'test_label':test_labels[idx],'pred_label':pred_labels[idx], 'SubjCode': SubjCode}, ignore_index=True)\n",
    "\n",
    "    # Suformuojame klasių numerių msyvus confusion matricai skaičiuoti, surandama confusion matrica\n",
    "    test_y = np.array(validation_set_stats[validation_set_stats['SubjCode']==SubjCode]['test_label']).astype('int') \n",
    "    # print(all_beats_attr.info())\n",
    "    pred_y = np.array(validation_set_stats[validation_set_stats['SubjCode']==SubjCode]['pred_label']).astype('int')\n",
    "   \n",
    "    # Atsikračius pūpsnių su klase = 3 ir suformavus masyvus, pred_y turi būti tokio pat ilgio, kaip ir test_y\n",
    "    if (len(test_y) != len(pred_y)):\n",
    "        raise Exception(f\"Klaida! SubjCode: {SubjCode}. Nesutampa test_y ir pred_y ilgiai\")     \n",
    "\n",
    "    # Skaičiuojame ir išvedame klasifikavimo lentelę\n",
    "    confusion = confusion_matrix(test_y, pred_y)\n",
    "    # print(confusion)\n",
    "    pd.set_option('display.precision',3)\n",
    "    show_confusion_matrix(confusion, class_names)\n",
    "\n",
    "# print('\\n')\n",
    "    prec,rec,fsc,sup = precision_recall_fscore_support(test_y, pred_y, labels=[0, 1, 2], zero_division=0)\n",
    "\n",
    "    str1 =f\"N:{int(sup[0]):>5} S:{(int(sup[1])):3} V:{int(sup[2]):3}\" \n",
    "    str2 = f\"  Nprec:{prec[0]:>5.2f} Nrec:{rec[0]:5.2f} Nfsc:{fsc[0]:5.2f}\"\n",
    "    str3 = f\"  Sprec:{prec[1]:>5.2f} Srec:{rec[1]:5.2f} Sfsc:{fsc[1]:5.2f}\"\n",
    "    str4 = f\"  Vprec:{prec[2]:>5.2f} Vrec:{rec[2]:5.2f} Vfsc:{fsc[2]:5.2f}\"\n",
    "    print(str1+str2+str3+str4)\n",
    "\n",
    "    # print(len(validation_set_stats))\n",
    "    # print(len(test_y))\n",
    "    # print(len(pred_y))\n",
    "\n",
    "end_time = time.time()\n",
    "print('\\n')\n",
    "runtime(end_time-start_time)\n",
    "\n",
    "# Sukūriame anotuotų ir automatiškai priskirtų klasių visų įrašų pūpsniams sąrašus \n",
    "validate_ind_lst = list(validation_set_stats['idx'])\n",
    "y_validate = np.array(validation_set_stats['test_label']).astype('int')\n",
    "y_predicted = np.array(validation_set_stats['pred_label']).astype('int')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fdd05f7b6e7f46fd1f1bbcbfdc9d8b4b1f98b078b306375c0cb77e6ad3f81a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ecg': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
