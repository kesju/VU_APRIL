{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS in my system :  linux\n",
      "\n",
      "Skriptas parodo anotacijų statistiką vietinėje ZIVE talpykloje\n",
      "Vietinės talpyklos aplankas: ZIVE_BUFFER_2022_03_24\n",
      "\n",
      "Viso pacientų: 4  EKG įrašų: 4\n",
      "\n",
      "Įrašų pasiskirstymas per pacientus\n",
      "                            N   S    V  F  U  count\n",
      "userID                                             \n",
      "6144c5b1bd0cc5a681275363  903   0    0  0  0      1\n",
      "6144c4fbbd0cc552e427535f  541   0  194  0  0      1\n",
      "613b1d673d08d4d1f3cdc8f8  656  12    0  0  0      1\n",
      "6190d4b23cd1d29db2303ce9  600  11    2  0  0      1\n",
      "Failų sąrašas ir rezultatai įrašyti į:  /home/kesju/DI/Data/MIT&ZIVE/ZIVE_BUFFER_2022_03_24/records/result.csv\n",
      "\n",
      "                    sum:  2700, 23, 196, 0, 0\n",
      "                  total:  2919\n",
      "\n",
      "Anotacijų pasiskirstymas per visus įrašus\n",
      "\n",
      "     file_name                    userId               recordingId    N   S    V  F  U  incl               recorded_at\n",
      "0  1630844.567  6144c5b1bd0cc5a681275363  6145aeb6bd0cc5e8392757d1  903   0    0  0  0     0  2021-09-05T12:22:47.000Z\n",
      "1  1631076.286  6144c4fbbd0cc552e427535f  6144cd8bbd0cc50b5e2753b6  541   0  194  0  0     0  2021-09-08T04:44:46.000Z\n",
      "2  1631134.867  613b1d673d08d4d1f3cdc8f8  613b22d43d08d407b7cdc9df  656  12    0  0  0     0  2021-09-08T21:01:07.000Z\n",
      "3  1636452.484  6190d4b23cd1d29db2303ce9  6190db883cd1d2635c3041c9  600  11    2  0  0     0  2021-11-09T10:08:04.000Z\n",
      "\n",
      "                                                     sum:  2700, 23, 196, 0, 0\n",
      "                                                   total:  2919\n",
      "\n",
      "\n",
      "userId: 613b1d673d08d4d1f3cdc8f8\n",
      "file_name: 1631134.867\n",
      "\n",
      "\n",
      "userId: 6144c4fbbd0cc552e427535f\n",
      "file_name: 1631076.286\n",
      "\n",
      "\n",
      "userId: 6144c5b1bd0cc5a681275363\n",
      "file_name: 1630844.567\n",
      "\n",
      "\n",
      "userId: 6190d4b23cd1d29db2303ce9\n",
      "file_name: 1636452.484\n"
     ]
    }
   ],
   "source": [
    "# Atnaujintas variantas, po to, kaip padaryti pakeitimai failų varduose 2022 03 26\n",
    "# reikia dar tvarkyti ///////////////////////////////////////////////////////////\n",
    "# Nuskaito ir parodo anotacijas visiems failams iš sąrašo. Sąrašas sukuriamas su 0_zive_suppl_list\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json, sys\n",
    "from pathlib import Path\n",
    "from icecream import ic\n",
    "\n",
    "def get_annotations_distribution(df_list, rec_dir, beats_annot, flag_incl):\n",
    "# Jei flag_incl == False, į požymį incl nereaguoti, sąrašą išvesti visiems EKG įrašams.\n",
    "# Jei flag_incl == True, sąrašą išvęsti tik tiems įrašams, kuriems incl ==1\n",
    "\n",
    "    # Nustatomas anotacijų pasiskirstymas per visus įrašus.\n",
    "    # Pasiruošimas ciklui per pacientų įrašus\n",
    "    labels_rec_all = pd.DataFrame(columns=beats_annot.keys(),dtype=int)\n",
    "    labels_rec_all.insert(0,\"file_name\",0)\n",
    "    labels_rec_all = labels_rec_all.astype({\"file_name\":str})\n",
    "    labels_rec_all.insert(1,\"userId\",0)\n",
    "    labels_rec_all = labels_rec_all.astype({\"userId\":str})\n",
    "    labels_rec_all.insert(2,\"recordingId\",0)\n",
    "    labels_rec_all = labels_rec_all.astype({\"recordingId\":str})\n",
    "    labels_rec_all.insert(8,\"incl\",0)\n",
    "    labels_rec_all = labels_rec_all.astype({\"incl\":int})\n",
    "    labels_rec_all.insert(9,\"recorded_at\",0)\n",
    "    labels_rec_all = labels_rec_all.astype({\"recorded_at\":str})\n",
    "\n",
    "    labels_rec = []\n",
    "\n",
    "    # Ciklas per pacientų įrašus\n",
    "    for ind in df_list.index:\n",
    "        file_name = df_list.loc[ind, \"file_name\"]\n",
    "        labels_rec = np.zeros(labels_rec_all.shape[1], dtype=int)\n",
    "        recordingId = df_list.loc[ind, \"recordingId\"]\n",
    "        file_name = df_list.loc[ind, \"file_name\"]\n",
    "\n",
    "\n",
    "        #  load data using Python JSON module\n",
    "        file_path = Path(rec_dir, file_name + '.json')\n",
    "        with open(file_path,'r', encoding='UTF-8', errors = 'ignore') as f:\n",
    "            data = json.loads(f.read())\n",
    "\n",
    "        df_rpeaks = pd.json_normalize(data, record_path =['rpeaks'])\n",
    "\n",
    "        atr_sample = df_rpeaks['sampleIndex'].to_numpy()\n",
    "        atr_symbol = df_rpeaks['annotationValue'].to_numpy()\n",
    "\n",
    "        # Ciklas per visas paciento įrašo anotacijas (simbolius)\n",
    "        for symbol in atr_symbol:\n",
    "            # Gaunamas anotacijos simbolio numeris anotacijų sąraše\n",
    "            label = beats_annot.get(symbol)\n",
    "            if (label == None):\n",
    "                continue\n",
    "            labels_rec[label] +=1\n",
    "\n",
    "        # timestamp_str = time.strftime(  '%m/%d/%Y :: %H:%M:%S', time.gmtime(os.path.getmtime(file_path))) \n",
    "        # timestamp_str = time.strftime(  '%m/%d/%Y :: %H:%M:%S', time.gmtime(os.path.getmtime(file_path))) \n",
    "        recorded_at = df_list.loc[ind, \"recorded_at\"]\n",
    "        # recorded_at = datetime.fromtimestamp(timestamp, tz=timezone.utc)\n",
    "\n",
    "        # Sumuojame į bendrą masyvą\n",
    "        dict = {'file_name':file_name, 'userId': data['userId'], 'recordingId':recordingId,  'N':labels_rec[0], 'S':labels_rec[1],\n",
    "         'V':labels_rec[2], 'F':labels_rec[3], 'U':labels_rec[4], 'incl':df_list.loc[ind, \"incl\"], 'recorded_at':recorded_at}\n",
    "        if (flag_incl == True):\n",
    "            if (df_list.loc[ind, \"incl\"] == 1): \n",
    "                labels_rec_all = labels_rec_all.append(dict, ignore_index = True)\n",
    "        else:\n",
    "            labels_rec_all = labels_rec_all.append(dict, ignore_index = True)\n",
    "\n",
    "    # Ciklo per pacientų įrašus pabaiga\n",
    "    return labels_rec_all\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "my_os=sys.platform\n",
    "print(\"OS in my system : \", my_os)\n",
    "\n",
    "if my_os != 'linux':\n",
    "    OS = 'Windows'\n",
    "else:  \n",
    "    OS = 'Ubuntu'\n",
    "\n",
    "# Pasiruošimas\n",
    "\n",
    "# //////////////// NURODOMI PARAMETRAI /////////////////////////////////////////////////////\n",
    "\n",
    "# Bendras duomenų aplankas\n",
    "\n",
    "if OS == 'Windows':\n",
    "    Duomenu_aplankas = 'D:\\DI\\Data\\MIT&ZIVE'   # variantas: Windows\n",
    "else:\n",
    "    Duomenu_aplankas = '/home/kesju/DI/Data/MIT&ZIVE'   # arba variantas: UBUNTU, be Docker\n",
    "\n",
    "# jei variantas Docker pasirenkame:\n",
    "# Duomenu_aplankas = '/Data/MIT&ZIVE'\n",
    "\n",
    "# Vietinės talpyklos aplankas\n",
    "db_folder = 'ZIVE_BUFFER_2022_03_24'\n",
    "\n",
    "# Aplankas su  EKG įrašais ir anotacijomis (.json)\n",
    "rec_folder = 'records'\n",
    "\n",
    "# ///////////////////////////////////////////////////////////////////////////////////////////\n",
    "print('\\nSkriptas parodo anotacijų statistiką vietinėje ZIVE talpykloje')\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 6000, \"display.max_columns\", 20)\n",
    "pd.set_option('display.width', 1000)\n",
    "# How to print an entire pandas DataFrame in Python\n",
    "# https://www.kite.com/python/answers/how-to-print-an-entire-pandas-dataframe-in-python\n",
    "\n",
    "# Nuoroda į aplanką su vietiniu EKG duomenų rinkiniu\n",
    "db_path = Path(Duomenu_aplankas, db_folder, rec_folder) # vietinė talpykla su jau esamais duomenimis arba tuščia\n",
    "print( 'Vietinės talpyklos aplankas:', db_folder)\n",
    "\n",
    "# Nuskaitomas įrašų sąrašas, suformuojamas atitinkamas dataframe df_list\n",
    "file_path = Path(db_path, 'list.json')\n",
    "with open(file_path,'r', encoding='UTF-8', errors = 'ignore') as f:\n",
    "    data = json.loads(f.read())\n",
    "df_list = pd.json_normalize(data, record_path =['data'])\n",
    "\n",
    "# Susirandame anotacijų pasiskirstymą per įrašus\n",
    "annot_list = ['N', 'S', 'V', 'F', 'U']\n",
    "# Susikuriame pagalbinį anotacijų žodyną - dictionary beats_annot\n",
    "nr_sequence = list(range(len(annot_list)))\n",
    "beats_annot = dict(zip(annot_list, nr_sequence))\n",
    "labels_rec_all = get_annotations_distribution(df_list, db_path, beats_annot, False)\n",
    "\n",
    "# Susirandame anotacijų pasiskirstymą per pacientus ir pacientų skaičių\n",
    "df_sum = labels_rec_all.groupby(['userId'],sort = False).sum()\n",
    "# https://sparkbyexamples.com/pandas/pandas-groupby-sum-examples/\n",
    "count = labels_rec_all['userId'].value_counts()\n",
    "print(f'\\nViso pacientų: {len(count)}  EKG įrašų: {len(labels_rec_all)}')\n",
    "print(f'\\nĮrašų pasiskirstymas per pacientus')\n",
    "count = count.rename(\"count\")\n",
    "frames = [df_sum, count]\n",
    "result = pd.concat(frames, axis = 1)\n",
    "result.index.rename ('userID', inplace= True)\n",
    "result.drop(labels=['incl'], axis=1, inplace=True)\n",
    "# https://www.shanelynn.ie/pandas-drop-delete-dataframe-rows-columns/\n",
    "print(result)\n",
    "\n",
    "filepath = Path(db_path, 'result.csv') \n",
    "result.to_csv(filepath)\n",
    "print(f'Failų sąrašas ir rezultatai įrašyti į:  {filepath}')    \n",
    "\n",
    "# Susumuojamos anotacijos\n",
    "suma = labels_rec_all.iloc[:,3:8].sum()\n",
    "print('\\n',' '*18, 'sum: ',str(suma.tolist())[1:-1])\n",
    "total = suma.sum()\n",
    "print(' '*17, 'total: ', total)\n",
    "\n",
    "# Parodomas anotacijų ir užduotų klasių pasiskirstymas per visus įrašus\n",
    "print(\"\\nAnotacijų pasiskirstymas per visus įrašus\\n\")\n",
    "print(labels_rec_all)\n",
    "suma = labels_rec_all.iloc[:,3:8].sum()\n",
    "print('\\n',' '*51, 'sum: ',str(suma.tolist())[1:-1])\n",
    "total = suma.sum()\n",
    "print(' '*50, 'total: ', total)\n",
    "\n",
    "\n",
    "grouped  = labels_rec_all.groupby('userId')\n",
    "for userId, group in grouped:\n",
    "    # print(group.dtypes)\n",
    "    print(\"\\n\")\n",
    "    # userId = get_rec_userId(rec_dir, userNr)\n",
    "    # print(f\"{'userNr:'} {userNr} {'userId:'} {userId}\" )\n",
    "    print(f\"{'userId:'} {userId}\" )\n",
    "    # tit1 = f\"{'userNr':>6} {'recNr':>6}  {'recId':>25} {'N':>8} {'S':>4} {'V':>4}\"\n",
    "    # tit2 = f\"{'Nprec':>8} {'Nrec':>5} {'Nfsc':>5}\"\n",
    "    # tit3 = f\"{'Sprec':>8} {'Srec':>5} {'Sfsc':>5}\"\n",
    "    # tit4 = f\"{'Vprec':>8} {'Vrec':>5} {'Vfsc':>5} {'Err%':>8} {'Noise%':>8}\"\n",
    "    # print(tit1+tit2+tit3+tit4)\n",
    "\n",
    "    for idx, row in group.iterrows():\n",
    "        print(f\"{'file_name:'} {str(row['file_name'])}\" )\n",
    "        # str1 =f\"{int(row['userNr']):>6} {int(row['recNr']):>6} {str(row['recId']):>26} {int(row['N']):>8} {int(row['S']):4} {int(row['V']):4}\" \n",
    "        # str2 = f\"{row['Nprec']:>8.2f} {row['Nrec']:5.2f} {row['Nfsc']:5.2f}\"\n",
    "        # str3 = f\"{row['Sprec']:>8.2f} {row['Srec']:5.2f} {row['Sfsc']:5.2f}\"\n",
    "        # str4 = f\"{row['Vprec']:>8.2f} {row['Vrec']:5.2f} {row['Vfsc']:5.2f} {row['Err%']:8.1f} {row['Noise%']:8.1f}\"\n",
    "        # print(str1+str2+str3+str4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fdd05f7b6e7f46fd1f1bbcbfdc9d8b4b1f98b078b306375c0cb77e6ad3f81a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ecg': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
